{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "801수업간략화중",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSv4m1xn7I5O"
      },
      "outputs": [],
      "source": [
        "# 불완전한 전처리\n",
        "\n",
        "# 기본 import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import  matplotlib.pyplot as plt\n",
        "\n",
        "# konlpy 인스톨, import\n",
        "! pip install kss konlpy\n",
        "import nltk, kss, konlpy\n",
        "\n",
        "# t_data2  [ kobill 문자열데이터 불러오기 ]\n",
        "from konlpy.corpus import kobill\n",
        "kobill.fileids() # kobill 파일이름 확인\n",
        "t_data2 = kobill.open('1809890.txt').read() # 파일 리드\n",
        "\n",
        "# t_data2_tk  [ t_data2 를 명사 기준으로 토크나이즈 ]  \n",
        "from konlpy.tag import Okt # 한글 형태소 태그 토크나이저\n",
        "tk = Okt()\n",
        "t_data2_tk = tk.nouns(t_data2) # 명사만\n",
        "t_data2_tk = [i for i in t_data2_tk if len(i)>1]  # 단어길이 2이상만 살린다\n",
        "\n",
        "# t_data2_tk 를 빈도순으로 1부터 오름차순 정렬한다\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tk = Tokenizer()\n",
        "tk.fit_on_texts(t_data2_tk)\n",
        "tk.index_word # 빈도순 정렬 : 1이 가장 높은 빈도\n",
        "tk.texts_to_sequences(t_data2_tk) # 정수화 (단어가 묶음이 아니라 하나 하나씩 정수화된 상태)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열데이터로드 > 문장토크나이즈 > 단어토크나이즈 > 정수인코딩 > 패딩\n",
        "\n",
        "# 기본 import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 텍스트 다운로드, import\n",
        "!wget https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt -O 2016-10-20.txt\n",
        "!pip install soynlp\n",
        "from soynlp import DoublespaceLineCorpus\n",
        " \n",
        "# t_data  [ kolaw 문자열데이터 불러오기 ]\n",
        "from konlpy.corpus import kolaw \n",
        "kolaw.fileids() # kolaw 파일이름 확인\n",
        "t_data = kolaw.open('constitution.txt').read() # 파일 리드 / 리드로 불러오면 str 타입으로 불러온다\n",
        "t_data = kolaw.open('constitution.txt') # 이렇게 불러와야 아래 더블스페이스에 쓸 수 있다\n",
        "\n",
        "# t_data_tk  [ t_data 를 문장 토크나이즈 ]     \n",
        "t_data_tk = DoublespaceLineCorpus(t_data.name,iter_sent=True) #이터센트트루 들어가면 문장토큰화 ( 생략시 문서로쪼개기에서 > 문장으로쪼개기의 차이)  # 모양 확인법 list(t_data_tk) \n",
        "\n",
        "# t_data_tk_tk  [ t_data_tk 를 단어 토크나이즈 ]\n",
        "from konlpy.tag import Okt\n",
        "tk = Okt()\n",
        "t_data_tk_tk = [] \n",
        "for i in t_data_tk:\n",
        "  t_data_tk2 = tk.nouns(i)\n",
        "  t_data_tk2 = [i for i in t_data_tk2 if len(i)>1] # 단어길이 2이상만 살림\n",
        "  t_data_tk_tk.append(t_data_tk2) # d 로 넣어버림\n",
        "\n",
        "# t_data_tk_tk_num [ t_data_tk_tk 를 정수화 ]\n",
        "tk = Tokenizer()\n",
        "tk.fit_on_texts(t_data_tk_tk)\n",
        "tk.index_word # 빈도순 1부터 오름차순 정렬\n",
        "t_data_tk_tk_num = tk.texts_to_sequences(t_data_tk_tk)  # d 를 정수화\n",
        "\n",
        "# t_data_tk_tk_num_pad [ t_data_tk_tk_num 을 패딩 ] \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "t_data_tk_tk_num_pad = pad_sequences(t_data_tk_tk_num, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "G9OjkN6INz3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열데이터 > 명사단어토크나이즈 > 텍스트화 > 그래프, 워드클라우드 시각화\n",
        "\n",
        "# 다운로드\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "!apt-get update -qq\n",
        "!apt-get install fonts-nanum* -qq\n",
        "\n",
        "# t_data 리드\n",
        "from konlpy.corpus import kolaw\n",
        "t_data = kolaw.open('constitution.txt').read()\n",
        "\n",
        "# t_data_tk  [ t_data 를 명사 단어 토크나이즈 ]\n",
        "from konlpy.tag import Okt # 단어토크나이즈\n",
        "tk = Okt()\n",
        "t_data_tk = tk.nouns(t_data) # 명사로 토크나이즈\n",
        "\n",
        "# t_data_tk_txt [ t_data_tk 를 텍스트화 ]\n",
        "from nltk import Text\n",
        "t_data_tk_txt = Text(t_data_tk,name=\"kolaw\")\n",
        "t_data_tk_txt\n",
        "\n",
        "# 그래프 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumGothic')\n",
        "t_data_tk_txt.plot(15)\n",
        "plt.show()\n",
        "\n",
        "# 워드클라우드 시각화\n",
        "from wordcloud import WordCloud\n",
        "wc=WordCloud(font_path='NanumGothic',width=1000,height=600,background_color='white')\n",
        "plt.imshow(wc.generate_from_frequencies(t_data_tk_txt.vocab()))\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "d8XNK8pRiafj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 > 단어토크나이즈 > 엔그램\n",
        "\n",
        "# 설치, import\n",
        "import nltk\n",
        "from nltk import bigrams,word_tokenize\n",
        "from nltk.util import ngrams\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 데이터 > 단어토크나이즈 > 엔그램(2) > fd로 확률 계산\n",
        "from nltk import ConditionalFreqDist\n",
        "t = 'l am a boy'\n",
        "t2 = 'you are a boy'\n",
        "t_tk = word_tokenize(t)  # t를 단어토크나이즈\n",
        "t_tk_ng = ngrams(t_tk,2,pad_left=True,pad_right=True,left_pad_symbol='SS',right_pad_symbol='SE') # tk를 엔그렘(2) # 모양확인 list(ng_d)\n",
        "t_tk_ng_fd = ConditionalFreqDist([(i[0],i[1])for i in t_tk_ng]) # 앞단어:뒷단어가뭐가나올까의 확률 1:100%  # i[0],i[1] 바이그램상태에서 앞단어-뒷단어  # fd['SS'] 라고 치면 'SS'다음 나올 문자 : 확률 / fd 출력하면 전체\n",
        "\n",
        "# 단어토크나이즈되어있는데이터 > 엔그램(2)\n",
        "문장 = movie_reviews.sents()[0]   # movie_reviews.sents() 는 단어토큰화까지 끝난 데이터 여기 [0]을 하면 단어들이 묶인 리스트 하나\n",
        "list(ngrams(문장,2,pad_left=True,pad_right=True,left_pad_symbol='SS',right_pad_symbol='SE')) # 엔그램(2) 후 바로 시각화 # 엔그램모양확인 list()\n"
      ],
      "metadata": {
        "id": "H5DDbZtvOS1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "emDV3ITgFmfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ConditionalFreqDist  # 앞단어:뒷단어가뭐가나올까의 확률 1:100%  # i[0],i[1] 바이그램상태에서 앞단어-뒷단어  # fd['SS'] 라고 치면 'SS'다음 나올 문자 : 확률 / fd 출력하면 전체\n",
        "from nltk.corpus import movie_reviews\n",
        "data_l=[]\n",
        "for 문장 in movie_reviews.sents():   # 단어토크나이즈끝난데이터, 단어들의묶음으로 되있음  즉 문장한덩어리가 들어감\n",
        "  bg_d = ngrams(문장,2,pad_left=True,pad_right=True,left_pad_symbol='SS',right_pad_symbol='SE')\n",
        "  data_l += [토큰_data for 토큰_data in bg_d]\n",
        "cfd = ConditionalFreqDist(data_l)"
      ],
      "metadata": {
        "id": "XUOyLDtuhdBS"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews.sents()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oenKiFfSzoKE",
        "outputId": "ee04fbeb-8d99-4f9b-d53d-669bc248b653"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.'], ...]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cfd.conditions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oTEOiaeGq5e",
        "outputId": "a5add124-89bc-452d-bc19-915bde581ebf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39769"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfd['SS'].most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6QjRo7pGyK1",
        "outputId": "69be6cfe-f101-418e-ad30-398c4c9b186f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 7965),\n",
              " ('it', 3038),\n",
              " ('i', 2350),\n",
              " ('but', 1754),\n",
              " ('he', 1642),\n",
              " ('in', 1629),\n",
              " ('this', 1625),\n",
              " ('and', 1607),\n",
              " ('there', 1280),\n",
              " ('.', 1230)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfd['the'].most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8qHqLDoHjx2",
        "outputId": "55f3b791-6001-470f-e51a-d1b20a3b53bd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('film', 4542),\n",
              " ('movie', 2147),\n",
              " ('story', 985),\n",
              " ('most', 945),\n",
              " ('first', 902),\n",
              " ('same', 774),\n",
              " ('only', 665),\n",
              " ('end', 664),\n",
              " ('best', 642),\n",
              " ('audience', 620)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfd['movie'].most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNwJ5osDHs5-",
        "outputId": "7b2d7a20-8baf-47c4-cd9b-acab299d2948"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 802),\n",
              " (',', 659),\n",
              " ('is', 469),\n",
              " (\"'\", 234),\n",
              " ('that', 210),\n",
              " ('was', 123),\n",
              " ('and', 105),\n",
              " ('with', 87),\n",
              " ('to', 72),\n",
              " ('has', 69)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfd['.'].most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbUBQgBXHxUH",
        "outputId": "2c61b9b2-c862-4448-e7dc-dc9788f376cd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('SE', 57626),\n",
              " ('.', 1893),\n",
              " ('\"', 1854),\n",
              " (')', 535),\n",
              " ('s', 129),\n",
              " ('i', 119),\n",
              " ('a', 118),\n",
              " ('and', 116),\n",
              " ('?', 108),\n",
              " ('the', 98)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import ConditionalProbDist,MLEProbDist"
      ],
      "metadata": {
        "id": "duyZ0ALGIG9A"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpd=ConditionalProbDist(cfd,MLEProbDist)"
      ],
      "metadata": {
        "id": "VQ1jmLrDIxjv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpd['the'].prob('movie')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzyVY-2UJE1e",
        "outputId": "17a533ce-dad1-434b-8bcb-52b6bf23d43c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0280547243528597"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpd['movie'].prob('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izvfxANdJRA3",
        "outputId": "95d0bea3-fd81-4a3b-aff8-61546fd01025"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13897071564720154"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpd['.'].prob('the')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izgSAqsMJiJ_",
        "outputId": "c9c26271-3ab6-4c66-d116-d74e40cae1eb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0014876434513328071"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P(SS<문장>SE)=P(시작단어|SS)*P(|)*P(|)*P(|)*P(|)*P(|)*P(SE|종료단어)"
      ],
      "metadata": {
        "id": "Qs_deC5aKDN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def s_sc_f(x):#바이그램 언어 모형의 확률 연산 함수\n",
        "  p=0.0\n",
        "  for i in range(len(x)-1):\n",
        "    c=x[i]\n",
        "    w=x[i+1]\n",
        "    p+=np.log(cpd[c].prob(w)+np.finfo(float).eps)\n",
        "  return np.exp(p)\n",
        "t_data=['the','movie','.']\n",
        "t_data2=['movie','.','the']\n",
        "s_sc_f(t_data),s_sc_f(t_data2)"
      ],
      "metadata": {
        "id": "KGReNPDhKDEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams#앞단어 뒷단어 data 생성용\n",
        "from nltk import ConditionalFreqDist# 문맥별 단어 빈도수 \n",
        "from nltk.probability import ConditionalProbDist #조건부 확률 \n",
        "from nltk.probability import MLEProbDist #최대 우도 추정 값 계산"
      ],
      "metadata": {
        "id": "uZd3Rk2PM_JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "SXb7ptH1Ss_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 수집"
      ],
      "metadata": {
        "id": "qATiX_yJQUHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "data=movie_reviews.sents()"
      ],
      "metadata": {
        "id": "kNjroJJgQFvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리<br>\n",
        "  -토큰화<br>\n",
        "  -정형화<br>\n",
        "  -정규화<br>"
      ],
      "metadata": {
        "id": "GgacaXxYQWmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_l=[]\n",
        "for 문장 in data:\n",
        "  bg=ngrams(문장, 2, pad_left=True,left_pad_symbol='SS',pad_right=True,right_pad_symbol='SE')\n",
        "  data_l+=[t for t in bg]"
      ],
      "metadata": {
        "id": "A9zkPV3yQWX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습"
      ],
      "metadata": {
        "id": "BDblXjZ7Rmmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfd = ConditionalFreqDist(data_l)\n",
        "cpd = ConditionalProbDist(cfd,MLEProbDist)"
      ],
      "metadata": {
        "id": "nusS9zDSRqyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 검증(생략)"
      ],
      "metadata": {
        "id": "x1TraH0LTA-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성 <자동 랜덤 문장 생성기>"
      ],
      "metadata": {
        "id": "jgZ9hIBkTFRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(10)\n",
        "cpd['SS'].generate()"
      ],
      "metadata": {
        "id": "FKG98x6vTLwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpd['when'].generate()"
      ],
      "metadata": {
        "id": "FASq5sjPUGZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpd['i'].generate()"
      ],
      "metadata": {
        "id": "qFaEcHgEUJ8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpd['still'].generate()"
      ],
      "metadata": {
        "id": "OB_nu2izULn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpd['know'].generate()"
      ],
      "metadata": {
        "id": "XP44rYQ_UO8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st='SS'\n",
        "all_l=[]\n",
        "import random\n",
        "random.seed(10)\n",
        "while True:##SS<문장>SE\n",
        "  st=cpd[st].generate()\n",
        "  all_l.append(st)\n",
        "  if st=='SE':\n",
        "    all_l.pop()\n",
        "    break\n",
        "생성된_data=' '.join(all_l)\n",
        "생성된_data\n"
      ],
      "metadata": {
        "id": "l-hp-ntgUSvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def 정리_생성(c='SS',s_n=10):\n",
        "  random.seed(s_n)\n",
        "  all_data=[]\n",
        "  while True:\n",
        "    if c not in cpd:\n",
        "      break\n",
        "    w = cpd[c].generate()\n",
        "    if w=='SE':\n",
        "      break\n",
        "    elif w in ['i','ii','iii']:\n",
        "      w2=w.upper()\n",
        "    elif w in [\"mr\", \"luc\", \"i\", \"robin\", \"williams\", \"cindy\", \"crawford\"]:\n",
        "      w2=w.title()\n",
        "    else:\n",
        "      w2=w\n",
        "    \n",
        "    if c==\"SS\":\n",
        "      all_data.append(w2.title())\n",
        "    elif c in [\"'\",\"\\\"\",'(']:\n",
        "      all_data.append(w2)\n",
        "    elif w in [\"'\",\",\",\".\",\")\",\":\",\";\",\"?\"]:\n",
        "      all_data.append(w2)\n",
        "    else:\n",
        "      all_data.append(\" \"+w2)\n",
        "    \n",
        "    c = w\n",
        "  if len(all_data)>0:\n",
        "    return ''.join(all_data)\n",
        "  return \"문장을 생성 할 수 없습니다.\""
      ],
      "metadata": {
        "id": "1Ve_m-HGWLu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "정리_생성()"
      ],
      "metadata": {
        "id": "0_ut-YAOZiBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "정리_생성('gdf')"
      ],
      "metadata": {
        "id": "5QhSG02NZ0RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "정리_생성('k',100)"
      ],
      "metadata": {
        "id": "tG1UIe7Lar4K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}