{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[샘플만들기] 카운터활용 문자열데이터 정수 인코딩(일단완성)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 기본 import \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 분석기 설치 및 import\n",
        "! pip install kss konlpy # 한국어분석기 kss, konlpy 설치\n",
        "import nltk, kss, konlpy # nltk 영어분석기 kss, konlpy한국어분석\n",
        "nltk.__version__  ,  konlpy.__version__ # 설치 확인 print(분석기.__버전__)\n",
        "\n",
        "# 토크나이저 import 및 실행\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence # 한국어 단어 토크나이저 : 단어 기준 토큰화 : 잘라주는\n",
        "from nltk.tokenize import word_tokenize # nltk 영어 단어 토크나이저\n",
        "from nltk.tokenize import WordPunctTokenizer # nltk 영어 단어 토크나이저 [클래스]\n",
        "from nltk.tokenize import TreebankWordTokenizer # nltk 영어 단어 토크나이저 [클래스]\n",
        "from nltk.tokenize import sent_tokenize # nltk 영어 [문장] 토크나이저\n",
        "nltk.download('punkt') # nltk 리소스 설치\n",
        "nltk.download('averaged_perceptron_tagger') # nltk 리소스 설치\n",
        "# 토크나이저 실행문 (여기서 단어란 명사가 아니라 끊을 수 있는 word의 단위를 말한다)\n",
        "# word_tokenize(영어.단어기준)\n",
        "# WordPunctTokenizer().tokenize(영어.단어기준)  # TreebankWordTokenizer().tokenize(영어.단어기준)\n",
        "# text_to_word_sequence(한글.단어기준)     # sent_tokenize(영어.문장기준)  \n",
        "\n",
        "# 토크나이저로 쪼갠 후 태그 분석\n",
        "from nltk.tag import  pos_tag # 영어태그 분석기\n",
        "from konlpy.tag import Okt, Kkma # Okt를 쓰자 # 한국어태그 분석기 [클래스]  # 형태소 분석 후 형태소를 기준으로 잘라냄\n",
        "# 태그 분석기 실행법\n",
        "# pos_tag(토크나이저실행문) # 태깅하기\n",
        "# Okt().pos(한국어)  # 한국어 단어 기준 품사 태깅 하기, 단어토크나이즈+태그 기능 #  Okt().morphs(한국어) : Okt로 한국어 단어 토큰화 하기  # Okt().nouns(한국어) : 명사(진짜명사)만 뽑겟다  # Kkma 는 Okt 와 사용법이 같다 기본적으로 범용적인 [Okt를 쓰자]\n"
      ],
      "metadata": {
        "id": "C1WAC79kphKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열 데이터 전처리 "
      ],
      "metadata": {
        "id": "mFk5HRZgN-K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\"\n",
        "문장토큰화_된_data = sent_tokenize(text) #문장토크나이저로 문장토큰화 문장별로 자르기\n",
        "문장토큰화_된_data # 3개의 문장 "
      ],
      "metadata": {
        "id": "dYGsqjtweAF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords # 불용어\n",
        "nltk.download('stopwords')\n",
        "단어모음 = {}\n",
        "t_data = []\n",
        "불용성단어 = set(stopwords.words('english')) #영어로구성된불용어모음집가져오기  # 중복안되게 set 으로 받았다\n",
        "불용성단어 #거를단어"
      ],
      "metadata": {
        "id": "tR8kPvRPeKS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for 문장 in 문장토큰화_된_data: \n",
        "    단어토큰화_된_data = word_tokenize(문장)      # 3개의 문장이 안에서 단어로 쪼개져있다\n",
        "    print(단어토큰화_된_data)"
      ],
      "metadata": {
        "id": "ASTx6XzArSQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for 문장 in 문장토큰화_된_data:        # 1 문장토큰화한 문장을 하나씩 뽑는다\n",
        "    단어토큰화_된_data = word_tokenize(문장) # 2 문장을 단어 토크나이저에 넣어서 단어별로 쪼갠다\n",
        "    l=[]  # 첫 문장의 단어들이 다 돌고 새 문장의 단어들이 들어올 때 리스트를 자꾸 새로 선언하는 것이다.\n",
        "    for 단어 in 단어토큰화_된_data:     # 3 단어토큰화된 데이터에서 단어를 하나씩 뽑는다\n",
        "        소문자화된_단어 = 단어.lower()  # 4 단어를 하나씩 뽑아서 소문자로 바꾼다  # 영어는 소문자로 통합 필수\n",
        "        if 소문자화된_단어 not in 불용성단어:  #  5  불용성단어집에 없는지 확인한다  불용성단어가 아니라면\n",
        "            if len(소문자화된_단어) > 2 :  # 6 단어의 길이가 3이상이라면 (알파벳짧은 것 의미 적을 거니까 배제해보자 2보다 큰 것을 담는다)\n",
        "                l.append(소문자화된_단어)   # 7 l리스트에 넣고\n",
        "                if 소문자화된_단어 not in 단어모음: # 그 단어가 단어모음에 없다면\n",
        "                    단어모음[소문자화된_단어]= 0  #  8 단어모음 딕셔너리에 그 단어를 key로 해서 밸류는 0을 넣는다 ( 키만 설정해주는 것이다)\n",
        "                단어모음[소문자화된_단어]+= 1    # 9 밸류를 +1해준다  ( 원래 단어모음에 있었다면 키가 이미 있으니까 여기서 +1만 해준다 )\n",
        "    t_data.append(l)  # 첫 줄에서 한 문장이 들어가서 단어별로 쪼개서 소문자화 하고 불용성단어가 아니며 3이상의 길이라면 어펜드 > 초기data가 문장3개라 리스트3개가 들어왔다\n",
        "t_data, 단어모음  #단어모음은 출현 수를 기록한 것이다\n",
        "# 토큰화 끝 : 결과적으로 t_data 는 소문자화, 불용어처리, 단어토큰화까지 3개를 동시에 처리한 데이터 (+짧은단어처리)\n",
        "# 정수인코딩 필요 : 빈도 수에 따른 숫자로 바꿔줘야함"
      ],
      "metadata": {
        "id": "eNiiS6lerql6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_data # 토큰화 : corpus 코퍼스(말뭉치) > 문장토큰화 > 단어토큰화     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrtlKny5bI9j",
        "outputId": "8a71f55f-5248-45bf-ca77-fb2e934e80a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['barber', 'person'],\n",
              " ['barber', 'good', 'person'],\n",
              " ['barber', 'huge', 'person'],\n",
              " ['knew', 'secret'],\n",
              " ['secret', 'kept', 'huge', 'secret'],\n",
              " ['huge', 'secret'],\n",
              " ['barber', 'kept', 'word'],\n",
              " ['barber', 'kept', 'word'],\n",
              " ['barber', 'kept', 'secret'],\n",
              " ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
              " ['barber', 'went', 'huge', 'mountain']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "단어모두모음= sum(t_data,[])  # 중복해서 들어감 > 같은 단어 여러번 들어감\n",
        "단어모두모음\n",
        "# 2차원 문자열데이터의 값을 중복제거는 못하고 순서 그대로 나열할 수 있음\n",
        "# sum(이터러블 문자    ,    []          ) #  문자의 차원을 두번 벗겨서 리스트에 나열 / 뒤 []에 뭘 넣으면 그냥 결과값 차원 1번 벗겨서 리스트 앞쪽에 위치시킴 \n",
        "# sum()함수  \n",
        "# sum(이터러블 숫자) # 숫자를 전부 더한 하나의 숫자 \n",
        "# sum(이터러블 숫자    ,   [숫자1개이상]) # , 뒤 숫자까지 더한 하나의 숫자"
      ],
      "metadata": {
        "id": "Un3TVetvblfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter # Counter 기반 '정수 인코딩'  Counter(단어모두모음) # 각 단어별 수 세기  # 단어모두모음 리스트에 있는 단어들의 각 개수를 딕셔너리로 만들어준다\n",
        " # 리스트에서 빈도 수 별로 딕셔너리로 엮고 빈도수 순위로 a위까지 뽑기\n",
        "# 카운터(리스트).most_common(숫자)  :  여기서 숫자는 최빈값(가장자주나오는수)을 뜻한다 숫자가 3이면 빈도수 순위 1,2,3 위가 순서대로 뽑힌다  먼저 카운터(리스트)로 리스트안의 값의 빈도수를 딕셔너리로 엮고 모스트커먼을 . 로 이어야 한다 \n",
        "살릴단어수 = 3  \n",
        "빈도별_단어 = Counter(단어모두모음).most_common(살릴단어수)\n",
        "빈도별_단어 # 단어모두모음 리스트에서 1,2,3 등으로 많이 있는 단어를 빈도수와 함께 뽑았다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U6kYCG_iyai",
        "outputId": "eb6d2f09-108d-4f54-e742-ddfcd5c3b7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈도가 가장 높은 단어를 1로 오름차순 정렬\n",
        "단어_인덱스 = {}\n",
        "i=0\n",
        "for 단어, 빈도수 in 빈도별_단어:\n",
        "    i+=1\n",
        "    단어_인덱스[단어]=i # 단어인덱스는 딕셔너리니까 각 단어를 키값으로 해서 i밸류를 넣어준다  \n",
        "단어_인덱스  # 빈도별_단어에 빈도 순서대로 담겨 있으니 그대로 i로 1,2,3 값을 주면 오름차순 정렬이 가능하다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hzPii-Upi0e",
        "outputId": "23261853-64c0-44c1-94c2-792e939532e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 1, 'huge': 3, 'secret': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 보캐불러리 만들기 = 단어_인덱스\n",
        "단어_인덱스['oov'] = len(단어_인덱스)+1   #oov 아웃오브보캐불러리를 oov키로 해서 최댓값으로 넣어준다\n",
        "단어_인덱스  #단어_인덱스_보캐불러리만 잃지않으면된다 보캐불러리만잇으면 아웃오브보캐를 무시할 수 잇다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJNXJHl2pqer",
        "outputId": "a45a6da1-49db-4b5a-d531-0cb18fd57460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 1, 'huge': 3, 'oov': 4, 'secret': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ec_data = []\n",
        "for 문장 in t_data:  # 리스트 한묶음 들어간다\n",
        "    ec_d = []  # ec_d인코딩된데이터\n",
        "    for 단어 in 문장:  # 한묵음의 리스트에서 단어 하나씩 뺀다\n",
        "        try: #트라이익셉예외처리   딕셔너리에서 없는 키값을 불러오려고 할 떄 에러가 나기 떄문에 처리하기위함\n",
        "            ec_d.append(단어_인덱스[단어]) # 단어_인덱스 보캐불러리에 있는 단어면 ec_d 리스트에 넣는다 딕셔너리니까 밸류값으로 들어가니 그 키에 해당하는 숫자가 들어간다 ec_d리스트에 들어간다\n",
        "        except KeyError:\n",
        "            ec_d.append(단어_인덱스['oov']) # 보캐불러리에 없다면 에러가 뜨고  # 단어_인덱스['oov'] 는 숫자 4 > 숫자4가 ec_d리스트로 들어간다\n",
        "    ec_data.append(ec_d)  # 한묶음 한묶음씩 넣어주기 위한 위치 설정 # 문장에서 단어를 다 뽑아서 숫자로 인코딩 후 그 한 묶음을 ec_data 리스트에 넣는다\n",
        "ec_data # 1,2,3 은 단어_인덱스 보캐불러리의 빈도순으로 나열된 단어들이고 숫자 4는 아웃오브보캐불러리\n",
        "# 정수인코딩 끝 : 단어를 빈도수 순으로 정렬한 단어_인덱스 (vocabulary) 를 만들고, 빈도수가 높은 순으로 1번부터 정수를 부여하는 방법"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkGaE4GspqxA",
        "outputId": "c5daa666-b311-4da5-fa1c-e4896dfcdbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 4],\n",
              " [1, 4, 4],\n",
              " [1, 3, 4],\n",
              " [4, 2],\n",
              " [2, 4, 3, 2],\n",
              " [3, 2],\n",
              " [1, 4, 4],\n",
              " [1, 4, 4],\n",
              " [1, 4, 2],\n",
              " [4, 4, 3, 2, 4, 1, 4],\n",
              " [1, 4, 3, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ImvS50XvjQQ",
        "outputId": "3dbfd91b-27a7-4a45-f51c-7398f6751010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['barber', 'person'],\n",
              " ['barber', 'good', 'person'],\n",
              " ['barber', 'huge', 'person'],\n",
              " ['knew', 'secret'],\n",
              " ['secret', 'kept', 'huge', 'secret'],\n",
              " ['huge', 'secret'],\n",
              " ['barber', 'kept', 'word'],\n",
              " ['barber', 'kept', 'word'],\n",
              " ['barber', 'kept', 'secret'],\n",
              " ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
              " ['barber', 'went', 'huge', 'mountain']]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    }
  ]
}