{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[샘플만들기]  nltk 문자열데이터 전처리  보캐불러리 딕셔너리 만들어서 하기 (일단완성) ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 기본 import \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 분석기 설치 및 import\n",
        "! pip install kss konlpy # 한국어분석기 kss, konlpy 설치\n",
        "import nltk, kss, konlpy # nltk 영어분석기 kss, konlpy한국어분석\n",
        "nltk.__version__  ,  konlpy.__version__ # 설치 확인 print(분석기.__버전__)\n",
        "\n",
        "# 토크나이저 import 및 실행\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence # 한국어 단어 토크나이저 : 단어 기준 토큰화 : 잘라주는\n",
        "from nltk.tokenize import word_tokenize # nltk 영어 단어 토크나이저\n",
        "from nltk.tokenize import WordPunctTokenizer # nltk 영어 단어 토크나이저 [클래스]\n",
        "from nltk.tokenize import TreebankWordTokenizer # nltk 영어 단어 토크나이저 [클래스]\n",
        "from nltk.tokenize import sent_tokenize # nltk 영어 [문장] 토크나이저\n",
        "nltk.download('punkt') # nltk 리소스 설치\n",
        "nltk.download('averaged_perceptron_tagger') # nltk 리소스 설치\n",
        "# 토크나이저 실행문 (여기서 단어란 명사가 아니라 끊을 수 있는 word의 단위를 말한다)\n",
        "# word_tokenize(영어.단어기준)\n",
        "# WordPunctTokenizer().tokenize(영어.단어기준)  # TreebankWordTokenizer().tokenize(영어.단어기준)\n",
        "# text_to_word_sequence(한글.단어기준)     # sent_tokenize(영어.문장기준)  \n",
        "\n",
        "# 토크나이저로 쪼갠 후 태그 분석\n",
        "from nltk.tag import  pos_tag # 영어태그 분석기\n",
        "from konlpy.tag import Okt, Kkma # Okt를 쓰자 # 한국어태그 분석기 [클래스]  # 형태소 분석 후 형태소를 기준으로 잘라냄\n",
        "# 태그 분석기 실행법\n",
        "# pos_tag(토크나이저실행문) # 태깅하기\n",
        "# Okt().pos(한국어)  # 한국어 단어 기준 품사 태깅 하기, 단어토크나이즈+태그 기능 #  Okt().morphs(한국어) : Okt로 한국어 단어 토큰화 하기  # Okt().nouns(한국어) : 명사(진짜명사)만 뽑겟다  # Kkma 는 Okt 와 사용법이 같다 기본적으로 범용적인 [Okt를 쓰자]\n"
      ],
      "metadata": {
        "id": "C1WAC79kphKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc87f7d9-fd2e-4743-a003-2183a4df7485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kss\n",
            "  Downloading kss-3.4.3.tar.gz (42.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.4 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.7 MB/s \n",
            "\u001b[?25hCollecting emoji==1.2.0\n",
            "  Downloading emoji-1.2.0-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from kss) (2022.6.2)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from kss) (8.13.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Building wheels for collected packages: kss\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-3.4.3-py3-none-any.whl size=42448068 sha256=ef3abbbb802010a4c9a335088cef1e3ebce15308b1bf0dad26bf70aa7addef9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/df/7d/0d0a58843aa7d267687671cf57274080bcfe8f79d59ed8f399\n",
            "Successfully built kss\n",
            "Installing collected packages: JPype1, emoji, kss, konlpy\n",
            "Successfully installed JPype1-1.4.0 emoji-1.2.0 konlpy-0.6.0 kss-3.4.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열 데이터 전처리 "
      ],
      "metadata": {
        "id": "mFk5HRZgN-K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\"\n",
        "문장토큰화_된_data = sent_tokenize(text) #문장토크나이저로 문장토큰화 문장별로 자르기\n",
        "문장토큰화_된_data # 3개의 문장 \n"
      ],
      "metadata": {
        "id": "dYGsqjtweAF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f9569b-c4d5-4608-c68c-0b7e13709d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A barber is a person.',\n",
              " 'a barber is good person.',\n",
              " 'a barber is huge person.',\n",
              " 'he Knew A Secret!',\n",
              " 'The Secret He Kept is huge secret.',\n",
              " 'Huge secret.',\n",
              " 'His barber kept his word.',\n",
              " 'a barber kept his word.',\n",
              " 'His barber kept his secret.',\n",
              " 'But keeping and keeping such a huge secret to himself was driving the barber crazy.',\n",
              " 'the barber went up a huge mountain.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords # 불용어\n",
        "nltk.download('stopwords')\n",
        "단어모음 = {}\n",
        "t_data = []\n",
        "불용성단어 = set(stopwords.words('english')) #영어로구성된불용어모음집가져오기  # 중복안되게 set 으로 받았다\n",
        "불용성단어 #거를단어"
      ],
      "metadata": {
        "id": "tR8kPvRPeKS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe9526c-bd49-4c7d-ab62-702387abd3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for 문장 in 문장토큰화_된_data: \n",
        "    단어토큰화_된_data = word_tokenize(문장)      # 3개의 문장이 안에서 단어로 쪼개져있다\n",
        "    print(단어토큰화_된_data)"
      ],
      "metadata": {
        "id": "ASTx6XzArSQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4653d509-44d7-469f-afd1-74054c206374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'barber', 'is', 'a', 'person', '.']\n",
            "['a', 'barber', 'is', 'good', 'person', '.']\n",
            "['a', 'barber', 'is', 'huge', 'person', '.']\n",
            "['he', 'Knew', 'A', 'Secret', '!']\n",
            "['The', 'Secret', 'He', 'Kept', 'is', 'huge', 'secret', '.']\n",
            "['Huge', 'secret', '.']\n",
            "['His', 'barber', 'kept', 'his', 'word', '.']\n",
            "['a', 'barber', 'kept', 'his', 'word', '.']\n",
            "['His', 'barber', 'kept', 'his', 'secret', '.']\n",
            "['But', 'keeping', 'and', 'keeping', 'such', 'a', 'huge', 'secret', 'to', 'himself', 'was', 'driving', 'the', 'barber', 'crazy', '.']\n",
            "['the', 'barber', 'went', 'up', 'a', 'huge', 'mountain', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for 문장 in 문장토큰화_된_data:        # 1 문장토큰화한 문장을 하나씩 뽑는다\n",
        "    단어토큰화_된_data = word_tokenize(문장) # 2 문장을 단어 토크나이저에 넣어서 단어별로 쪼갠다\n",
        "    l=[]  # 첫 문장의 단어들이 다 돌고 새 문장의 단어들이 들어올 때 리스트를 자꾸 새로 선언하는 것이다.\n",
        "    for 단어 in 단어토큰화_된_data:     # 3 단어토큰화된 데이터에서 단어를 하나씩 뽑는다\n",
        "        소문자화된_단어 = 단어.lower()  # 4 단어를 하나씩 뽑아서 소문자로 바꾼다  # 영어는 소문자로 통합 필수\n",
        "        if 소문자화된_단어 not in 불용성단어:  #  5  불용성단어집에 없는지 확인한다  불용성단어가 아니라면\n",
        "            if len(소문자화된_단어) > 2 :  # 6 단어의 길이가 3이상이라면 (알파벳짧은 것 의미 적을 거니까 배제해보자 2보다 큰 것을 담는다)\n",
        "                l.append(소문자화된_단어)   # 7 l리스트에 넣고\n",
        "                if 소문자화된_단어 not in 단어모음: # 그 단어가 단어모음에 없다면\n",
        "                    단어모음[소문자화된_단어]= 0  #  8 단어모음 딕셔너리에 그 단어를 key로 해서 밸류는 0을 넣는다 ( 키만 설정해주는 것이다)\n",
        "                단어모음[소문자화된_단어]+= 1    # 9 밸류를 +1해준다  ( 원래 단어모음에 있었다면 키가 이미 있으니까 여기서 +1만 해준다 )\n",
        "    t_data.append(l)  # 첫 줄에서 한 문장이 들어가서 단어별로 쪼개서 소문자화 하고 불용성단어가 아니며 3이상의 길이라면 어펜드 > 초기data가 문장3개라 리스트3개가 들어왔다\n",
        "t_data, 단어모음  #단어모음은 출현 수를 기록한 것이다\n",
        "# 결과적으로 t_data 는 소문자화, 불용어처리, 단어토큰화까지 3개를 동시에 처리한 데이터 (+짧은단어처리) "
      ],
      "metadata": {
        "id": "eNiiS6lerql6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebf0abb-9137-4257-c1df-4e8955d5ea49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['barber', 'person'],\n",
              "  ['barber', 'good', 'person'],\n",
              "  ['barber', 'huge', 'person'],\n",
              "  ['knew', 'secret'],\n",
              "  ['secret', 'kept', 'huge', 'secret'],\n",
              "  ['huge', 'secret'],\n",
              "  ['barber', 'kept', 'word'],\n",
              "  ['barber', 'kept', 'word'],\n",
              "  ['barber', 'kept', 'secret'],\n",
              "  ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
              "  ['barber', 'went', 'huge', 'mountain']],\n",
              " {'barber': 8,\n",
              "  'crazy': 1,\n",
              "  'driving': 1,\n",
              "  'good': 1,\n",
              "  'huge': 5,\n",
              "  'keeping': 2,\n",
              "  'kept': 4,\n",
              "  'knew': 1,\n",
              "  'mountain': 1,\n",
              "  'person': 3,\n",
              "  'secret': 6,\n",
              "  'went': 1,\n",
              "  'word': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3cMrHRWWfQ0",
        "outputId": "5f0973dc-9112-4e6b-b1a9-dbca7f86c4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['barber', 'person'],\n",
              " ['barber', 'good', 'person'],\n",
              " ['barber', 'huge', 'person'],\n",
              " ['knew', 'secret'],\n",
              " ['secret', 'kept', 'huge', 'secret'],\n",
              " ['huge', 'secret'],\n",
              " ['barber', 'kept', 'word'],\n",
              " ['barber', 'kept', 'word'],\n",
              " ['barber', 'kept', 'secret'],\n",
              " ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
              " ['barber', 'went', 'huge', 'mountain']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "정렬된_단어모음 = sorted(단어모음.items(), key=lambda x:x[1] , reverse = True )  # reverse = 디폴트는 False  / reverse = True의 경우 내림차순 정렬 > 즉 빈도가 높은 순으로 정렬했다   # sorted 나열의기준과 키를 같이지정하고싶을떄 솔티드  # key=lambda x:x[1] 은  ('barber',8)에서 1인덱이 8이니까 숫자 순으로 정렬하겠다는 건데 뒤에서 리버스트루로 내림차순 정렬을 했으니 8부터 내림차순 정렬이 된다. 인덱 0 으로 줄경우 알파벳순 내림차순 정렬.  #.items() 를 안붙이면 딕셔너리라서 키값만 뽑는다\n",
        "정렬된_단어모음\n",
        "# 카운터를 쓸 경우 이 부분만 다르다 # 카운터를 쓰면 2줄 적게 쓴다 14줄 vs 16줄\n",
        "# 여기서 정렬된_단어모음 이랑 빈도별_단어랑 같다 단 정렬된_단어모음은 단어모음 으로 만들고 빈도별_단어는 t_data로 만든다\n",
        "# from collections import Counter\n",
        "# 단어모두모음= sum(t_data,[])  # 중복해서 들어감 > 같은 단어 여러번 들어감\n",
        "# 살릴단어수 = 3  \n",
        "# 빈도별_단어 = Counter(단어모두모음).most_common(살릴단어수)\n",
        "# 살릴단어수 넣는 순서도 다르다"
      ],
      "metadata": {
        "id": "Kmvl8wR1wzCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72be5cf1-c518-4b1b-fdd9-aaa1e2aeb889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8),\n",
              " ('secret', 6),\n",
              " ('huge', 5),\n",
              " ('kept', 4),\n",
              " ('person', 3),\n",
              " ('word', 2),\n",
              " ('keeping', 2),\n",
              " ('good', 1),\n",
              " ('knew', 1),\n",
              " ('driving', 1),\n",
              " ('crazy', 1),\n",
              " ('went', 1),\n",
              " ('mountain', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈도 낮은 걸 버리고, 빈도순으로 1부터 오름차순 정렬\n",
        "단어_인덱스={}   #문자대신 컴퓨터가이해할수잇는숫자로 바꾸기\n",
        "i=0\n",
        "for (단어, 빈도수) in 정렬된_단어모음:  \n",
        "    if 빈도수 > 3:   #빈도낮은걸 버리겟다 \n",
        "        i+=1\n",
        "        단어_인덱스[단어]=i # 단어_인덱스 딕셔너리에  키값으로 [단어]로 밸류를 i로 \n",
        "단어_인덱스\n",
        "# 각 숫자의 의미 : barber가 첫번째로 들어가고 secret이 두번째로 들어감 > 즉 빈도순으로 오름차순으로 정렬이 된 것 "
      ],
      "metadata": {
        "id": "X7ngo49Hewaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc54a42b-f082-489a-bd31-f08ddced8709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 1, 'huge': 3, 'kept': 4, 'secret': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 비중이 높은 것만 살리기\n",
        "살릴단어수 = 3\n",
        "제거_data=[단어 for 단어, i in 단어_인덱스.items() if i > 살릴단어수 ]  #비중높은것만살리기위해\n",
        "for i in 제거_data:\n",
        "    del 단어_인덱스[i]\n",
        "단어_인덱스 # 보캐불러리를 완성했다."
      ],
      "metadata": {
        "id": "yaWoNnWXypRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca92bb1-d479-4e09-adfe-6917e09007fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 1, 'huge': 3, 'secret': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 보캐불러리 만들기 = 단어_인덱스\n",
        "단어_인덱스['oov'] = len(단어_인덱스)+1   #oov 아웃오브보캐불러리를 oov키로 해서 최댓값으로 넣어준다\n",
        "단어_인덱스  #단어_인덱스_보캐불러리만 잃지않으면된다 보캐불러리만잇으면 아웃오브보캐를 무시할 수 잇다"
      ],
      "metadata": {
        "id": "7lekvujOC4zJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12ad3f2-6973-462a-83b4-b3c30953ac66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 1, 'huge': 3, 'oov': 4, 'secret': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ec_data = []\n",
        "for 문장 in t_data:  # 리스트 한묶음 들어간다\n",
        "    ec_d = []  # ec_d인코딩된데이터\n",
        "    for 단어 in 문장:  # 한묵음의 리스트에서 단어 하나씩 뺀다\n",
        "        try: #트라이익셉예외처리   딕셔너리에서 없는 키값을 불러오려고 할 떄 에러가 나기 떄문에 처리하기위함\n",
        "            ec_d.append(단어_인덱스[단어]) # 단어_인덱스 보캐불러리에 있는 단어면 ec_d 리스트에 넣는다 딕셔너리니까 밸류값으로 들어가니 그 키에 해당하는 숫자가 들어간다 ec_d리스트에 들어간다\n",
        "        except KeyError:\n",
        "            ec_d.append(단어_인덱스['oov']) # 보캐불러리에 없다면 에러가 뜨고  # 단어_인덱스['oov'] 는 숫자 4 > 숫자4가 ec_d리스트로 들어간다\n",
        "    ec_data.append(ec_d)  # 한묶음 한묶음씩 넣어주기 위한 위치 설정 # 문장에서 단어를 다 뽑아서 숫자로 인코딩 후 그 한 묶음을 ec_data 리스트에 넣는다\n",
        "ec_data # 1,2,3 은 단어_인덱스 보캐불러리의 빈도순으로 나열된 단어들이고 숫자 4는 아웃오브보캐불러리\n",
        "# 정수인코딩 끝 : 단어를 빈도수 순으로 정렬한 단어_인덱스 (vocabulary) 를 만들고, 빈도수가 높은 순으로 1번부터 정수를 부여하는 방법"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6m1C7Sm4cPF",
        "outputId": "728e4a39-fbe8-4ca3-e7f3-ee0550162e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 4],\n",
              " [1, 4, 4],\n",
              " [1, 3, 4],\n",
              " [4, 2],\n",
              " [2, 4, 3, 2],\n",
              " [3, 2],\n",
              " [1, 4, 4],\n",
              " [1, 4, 4],\n",
              " [1, 4, 2],\n",
              " [4, 4, 3, 2, 4, 1, 4],\n",
              " [1, 4, 3, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}