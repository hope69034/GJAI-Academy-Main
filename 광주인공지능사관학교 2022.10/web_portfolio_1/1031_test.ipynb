{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lXo0qjC9PlVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMLSebHK94Y3",
        "outputId": "83c07303-c150-4e12-9411-41a5067eb821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F  # F : 테스트 로스 연산 함수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScXWK6zV94WQ",
        "outputId": "74316b77-348b-46cf-ca01-7b8444f5acf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (4.1.1)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=34daa12e6ae5060181a7cd33406e9642df4e6080ede66ed3a37bcce0b1303963\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## check point // 모델 파일 경로 \n",
        "PATH1 = '/content/drive/MyDrive/sdproject/scalp_weights/'+'aram_model1.pt'   \n",
        "PATH2 = '/content/drive/MyDrive/sdproject/scalp_weights/'+'aram_model2.pt'   \n",
        "PATH3 = '/content/drive/MyDrive/sdproject/scalp_weights/'+'aram_model3.pt'   \n",
        "PATH4 = '/content/drive/MyDrive/sdproject/scalp_weights/'+'aram_model4.pt'   \n",
        "PATH5 = '/content/drive/MyDrive/sdproject/scalp_weights/'+'aram_model5.pt'   \n",
        "PATH6 = '/content/drive/MyDrive/sdproject/scalp_weights/'+'aram_model6.pt'   "
      ],
      "metadata": {
        "id": "DGGVcq_Q94TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델 check point // 모델 1~6\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model1 = torch.load(PATH1, map_location=device)\n",
        "model2 = torch.load(PATH2, map_location=device)\n",
        "model3 = torch.load(PATH3, map_location=device)\n",
        "model4 = torch.load(PATH4, map_location=device)\n",
        "model5 = torch.load(PATH5, map_location=device)\n",
        "model6 = torch.load(PATH6, map_location=device)"
      ],
      "metadata": {
        "id": "9ke99k_p94Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 전처리\n",
        "# 전처리 규칙\n",
        "transforms_test = transforms.Compose([                                      \n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BOX), \n",
        "                                        transforms.ToTensor(), \n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
        "                                      ])\n",
        "# check point // root 경로 폴더 속 jpg를 전처리, 텐서화 (root 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함) \n",
        "testset1 = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/sdproject/train_data/model1/test' ,\n",
        "                    transform = transforms_test)\n",
        "testset2 = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/sdproject/train_data/model2/test' ,\n",
        "                    transform = transforms_test)\n",
        "testset3 = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/sdproject/train_data/model3/test' ,\n",
        "                    transform = transforms_test)\n",
        "testset4 = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/sdproject/train_data/model4/test' ,\n",
        "                    transform = transforms_test)\n",
        "testset5 = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/sdproject/train_data/model5/test' ,\n",
        "                    transform = transforms_test)\n",
        "testset6 = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/sdproject/train_data/model6/test' ,\n",
        "                    transform = transforms_test)\n",
        "# check point // 로더 : 전처리한 이미지와 라벨링된 정답값을 튜플로 묶음 for data, target in testloader: 에서 data는 데이터의 특징  target은 데이터의 정답값\n",
        "testloader1 = DataLoader(testset1, batch_size=2, shuffle=False, num_workers=0) \n",
        "testloader2 = DataLoader(testset2, batch_size=2, shuffle=False, num_workers=0) \n",
        "testloader3 = DataLoader(testset3, batch_size=2, shuffle=False, num_workers=0) \n",
        "testloader4 = DataLoader(testset4, batch_size=2, shuffle=False, num_workers=0) \n",
        "testloader5 = DataLoader(testset5, batch_size=2, shuffle=False, num_workers=0) \n",
        "testloader6 = DataLoader(testset6, batch_size=2, shuffle=False, num_workers=0) "
      ],
      "metadata": {
        "id": "iYJNqy84-T9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcnTI4Q19QFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbde1d0a-5803-4035-c655-d8a860dae7bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 238/238 [04:38<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set Accuracy: 289/476 (60.71%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 331/331 [07:27<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set Accuracy: 411/662 (62.08%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 512/512 [12:15<00:00,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set Accuracy: 634/1024 (61.91%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 197/197 [04:26<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set Accuracy: 281/394 (71.32%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 310/310 [07:17<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set Accuracy: 370/620 (59.68%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 577/577 [12:32<00:00,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set Accuracy: 773/1154 (66.98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## 테스트 펑션\n",
        "# check point // 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "model1.eval() \n",
        "model2.eval()\n",
        "model3.eval() \n",
        "model4.eval()\n",
        "model5.eval() \n",
        "model6.eval()\n",
        "\n",
        "# check point //\n",
        "# output_list = []\n",
        "# test_loss = 0\n",
        " \n",
        "# 펑션\n",
        "if __name__ == '__main__':\n",
        "    with torch.no_grad(): \n",
        "    # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "\n",
        "    \n",
        "            # model1\n",
        "            correct = 0\n",
        "            for data, target in tqdm(testloader1):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model1(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                # output_list.append(output)\n",
        "                #test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "            print('\\nTest set Accuracy: {}/{} ({:.2f}%)\\n'.format(correct, len(testloader1.dataset), 100. * correct / len(testloader1.dataset)))\n",
        "\n",
        "            # model2\n",
        "            correct = 0   \n",
        "            for data, target in tqdm(testloader2):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model2(data)  \n",
        "                pred = output.argmax(dim=1, keepdim=True) \n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            print('\\nTest set Accuracy: {}/{} ({:.2f}%)\\n'.format(correct, len(testloader2.dataset), 100. * correct / len(testloader2.dataset)))\n",
        "\n",
        "            # model3\n",
        "            correct = 0   \n",
        "            for data, target in tqdm(testloader3):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model3(data)  \n",
        "                pred = output.argmax(dim=1, keepdim=True) \n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            print('\\nTest set Accuracy: {}/{} ({:.2f}%)\\n'.format(correct, len(testloader3.dataset), 100. * correct / len(testloader3.dataset)))\n",
        "\n",
        "            # model4\n",
        "            correct = 0   \n",
        "            for data, target in tqdm(testloader4):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model4(data)  \n",
        "                pred = output.argmax(dim=1, keepdim=True) \n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            print('\\nTest set Accuracy: {}/{} ({:.2f}%)\\n'.format(correct, len(testloader4.dataset), 100. * correct / len(testloader4.dataset)))\n",
        "\n",
        "            # model5\n",
        "            correct = 0   \n",
        "            for data, target in tqdm(testloader5):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model5(data)  \n",
        "                pred = output.argmax(dim=1, keepdim=True) \n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            print('\\nTest set Accuracy: {}/{} ({:.2f}%)\\n'.format(correct, len(testloader5.dataset), 100. * correct / len(testloader5.dataset)))\n",
        "\n",
        "            # model6\n",
        "            correct = 0   \n",
        "            for data, target in tqdm(testloader6):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model6(data)  \n",
        "                pred = output.argmax(dim=1, keepdim=True) \n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            print('\\nTest set Accuracy: {}/{} ({:.2f}%)\\n'.format(correct, len(testloader6.dataset), 100. * correct / len(testloader6.dataset)))\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 출력\n",
        "# 0:양호, 1:경증, 2:중등도, 3:중증\n",
        "# test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader1.dataset), 100. * correct / len(testloader1.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader2.dataset), 100. * correct / len(testloader2.dataset)))\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader3.dataset), 100. * correct / len(testloader3.dataset)))\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader4.dataset), 100. * correct / len(testloader4.dataset)))\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader5.dataset), 100. * correct / len(testloader5.dataset)))\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader6.dataset), 100. * correct / len(testloader6.dataset)))\n",
        "# 로스, 아큐러시 출력\n",
        "# print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "# 업로드 이미지에 대한 output predict 값\n",
        "# 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "# m1output = output_list[-1]\n",
        "# m1predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "# print('model1 미세각질 output :', m1output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "# print('model1 미세각질 predict :',m1predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값"
      ],
      "metadata": {
        "id": "RUu88j-SATjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "100%|██████████| 238/238 [04:25<00:00,  1.12s/it]\n",
        "Test set Accuracy: 289/476 (60.71%)\n",
        "\n",
        "모델2 학습 efficientnet-b0 hyper_param_batch = 8 num_epochs = 10 총 200분\n",
        "train Loss: 0.8251 Acc: 61.8783\n",
        "val Loss: 0.9141 Acc: 58.1440\n",
        "Test set Accuracy: 411/662 (62.08%) \n",
        "\n",
        "100%|██████████| 359/359 [06:36<00:00,  1.11s/it]\n",
        "Test set Accuracy: 461/718 (64.21%)\n",
        "\n",
        "100%|██████████| 197/197 [03:58<00:00,  1.21s/it]\n",
        "Test set Accuracy: 281/394 (71.32%)\n",
        "\n",
        "100%|██████████| 310/310 [05:33<00:00,  1.07s/it]\n",
        "Test set Accuracy: 370/620 (59.68%)\n",
        "\n",
        "\n",
        "100%|██████████| 577/577 [12:47<00:00,  1.33s/it]\n",
        "Test set Accuracy: 773/1154 (66.98%)"
      ],
      "metadata": {
        "id": "-1iZmQJI9Gqd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}