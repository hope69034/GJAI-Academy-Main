{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "코랩용모델1테스트코드최종.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP3C2Wu4mJaO",
        "outputId": "37e97ce2-0ae6-4540-c93f-6876244dbb9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (4.1.1)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=5a2df34dcfa2a95f60032249a2d16ef8a226bd674eb6f7d46fb17e3c1ea19d90\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1084/1084 [04:06<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0'),\n",
              " tensor([[2]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "# PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "# model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "# testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "# model1.eval()\n",
        "# output = model1(data) \n",
        "\n",
        "# 구글드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  \n",
        "# 모델.pt파일 경로\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # 모델1\n",
        "# PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "# CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델1 불러오기\n",
        "!pip install efficientnet_pytorch\n",
        "model1 = torch.load(PATH, map_location=device)\n",
        "# 모델1 파라미터 불러오기\n",
        "# model1_p = torch.load(PATH2, map_location=device)\n",
        "## test 이미지파일 전처리, 텐서화\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "# 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "transforms_test = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "# root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test', \n",
        "\t\t\t\t\ttransform = transforms_test)\n",
        "## 확인\n",
        "testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "# rgb three channel 이니까 3\n",
        "# 높이 넓이 600 600 리사이즈\n",
        "# 전처리 정상 완료 확인\n",
        "# DataLoader를 통해 네트워크에 올리기\n",
        "from torch.utils.data import Dataset,DataLoader \n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "# dataiter = iter(testloader)\n",
        "# images = dataiter.next()\n",
        "# images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "output_list = []\n",
        "model1.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "correct = 0\n",
        "# 로스 연산\n",
        "# import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "# test_loss = 0\n",
        "from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "            for data, target in tqdm(testloader):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model1(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                output_list.append(output);\n",
        "                # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "# test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "# 로스, 아큐러시 출력\n",
        "# print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "# 업로드 이미지에 대한 output predict 값\n",
        "# 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "#  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "print(output_list[-1]) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "print(output_list[-1].argmax(dim=1, keepdim=True))   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6QWXoYO7mSS2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}