{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_23_sd_project_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 구글드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  \n",
        "\n",
        "# 모델1 test set 아큐러시, 로스 측정\n",
        "\n",
        "# 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "# PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "# model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "# testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "# model1.eval()\n",
        "# output = model1(data) \n",
        "\n",
        "# 구글드라이브 마운트\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')  \n",
        "# 모델.pt파일 경로\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # 모델1\n",
        "# PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "# CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델1 불러오기\n",
        "!pip install efficientnet_pytorch\n",
        "model1 = torch.load(PATH, map_location=device)\n",
        "# 모델1 파라미터 불러오기\n",
        "# model1_p = torch.load(PATH2, map_location=device)\n",
        "## test 이미지파일 전처리, 텐서화\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "# 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "transforms_test = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "# root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test', \n",
        "\t\t\t\t\ttransform = transforms_test)\n",
        "## 확인\n",
        "testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "# rgb three channel 이니까 3\n",
        "# 높이 넓이 600 600 리사이즈\n",
        "# 전처리 정상 완료 확인\n",
        "# DataLoader를 통해 네트워크에 올리기\n",
        "from torch.utils.data import Dataset,DataLoader \n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "# dataiter = iter(testloader)\n",
        "# images = dataiter.next()\n",
        "# images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "# output_list = []\n",
        "model1.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "correct = 0\n",
        "# 로스 연산\n",
        "import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "test_loss = 0\n",
        "from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "            for data, target in tqdm(testloader):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model1(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                # output_list.append(output);\n",
        "                test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "# 로스, 아큐러시 출력\n",
        "print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "# 업로드 이미지에 대한 output predict 값\n",
        "# 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "#  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "#m1output = output_list[-1]\n",
        "#m1predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "#print()\n",
        "#print()\n",
        "#print('model1 미세각질 output :', m1output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "#print('model1 미세각질 predict :',m1predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "# 모델1 upload file predict\n",
        "\n",
        "# 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "# PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "# model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "# testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "# model1.eval()\n",
        "# output = model1(data) \n",
        "\n",
        "# 구글드라이브 마운트\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')  \n",
        "# 모델.pt파일 경로\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # 모델1\n",
        "# PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "# CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델1 불러오기\n",
        "!pip install efficientnet_pytorch\n",
        "model1 = torch.load(PATH, map_location=device)\n",
        "# 모델1 파라미터 불러오기\n",
        "# model1_p = torch.load(PATH2, map_location=device)\n",
        "## test 이미지파일 전처리, 텐서화\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "# 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "transforms_test = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "# root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/upload', \n",
        "\t\t\t\t\ttransform = transforms_test)\n",
        "## 확인\n",
        "testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "# rgb three channel 이니까 3\n",
        "# 높이 넓이 600 600 리사이즈\n",
        "# 전처리 정상 완료 확인\n",
        "# DataLoader를 통해 네트워크에 올리기\n",
        "from torch.utils.data import Dataset,DataLoader \n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "# dataiter = iter(testloader)\n",
        "# images = dataiter.next()\n",
        "# images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "output_list = []\n",
        "model1.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "correct = 0\n",
        "# 로스 연산\n",
        "# import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "# test_loss = 0\n",
        "from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "            for data, target in tqdm(testloader):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model1(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                output_list.append(output)\n",
        "                # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "# test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "# 로스, 아큐러시 출력\n",
        "# print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "# 업로드 이미지에 대한 output predict 값\n",
        "# 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "#  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "m1output = output_list[-1]\n",
        "m1predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "print()\n",
        "print()\n",
        "print('model1 미세각질 output :', m1output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "print('model1 미세각질 predict :',m1predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "# 모델2 upload file predict\n",
        "\n",
        "# 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "# PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "# model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "# testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "# model1.eval()\n",
        "# output = model1(data) \n",
        "\n",
        "# 구글드라이브 마운트\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')  \n",
        "# 모델.pt파일 경로\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model2.pt'  # 모델1\n",
        "# PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "# CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "# import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델1 불러오기\n",
        "# !pip install efficientnet_pytorch\n",
        "model2 = torch.load(PATH, map_location=device)\n",
        "# 모델1 파라미터 불러오기\n",
        "# model1_p = torch.load(PATH2, map_location=device)\n",
        "## test 이미지파일 전처리, 텐서화\n",
        "# import torchvision\n",
        "# from torchvision import transforms\n",
        "# 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "transforms_test = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "# root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/upload', \n",
        "\t\t\t\t\ttransform = transforms_test)\n",
        "## 확인\n",
        "testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "# rgb three channel 이니까 3\n",
        "# 높이 넓이 600 600 리사이즈\n",
        "# 전처리 정상 완료 확인\n",
        "# DataLoader를 통해 네트워크에 올리기\n",
        "# from torch.utils.data import Dataset,DataLoader \n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "# dataiter = iter(testloader)\n",
        "# images = dataiter.next()\n",
        "# images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "output_list = []\n",
        "model2.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "correct = 0\n",
        "# 로스 연산\n",
        "# import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "# test_loss = 0\n",
        "# from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "            for data, target in tqdm(testloader):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model2(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                output_list.append(output);\n",
        "                # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "# test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "# 로스, 아큐러시 출력\n",
        "# print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "# 업로드 이미지에 대한 output predict 값\n",
        "# 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "#  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "m2output = output_list[-1]\n",
        "m2predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "print()\n",
        "print()\n",
        "print('model2 피지과다 output :', m2output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "print('model2 피지과다 predict :',m2predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "# 모델3 upload file predict\n",
        " \n",
        "# 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "# PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "# model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "# testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "# model1.eval()\n",
        "# output = model1(data) \n",
        "\n",
        "# 구글드라이브 마운트\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')  \n",
        "# 모델.pt파일 경로\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model3.pt'  # 모델1\n",
        "# PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "# CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "# import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델1 불러오기\n",
        "# !pip install efficientnet_pytorch\n",
        "model3 = torch.load(PATH, map_location=device)\n",
        "# 모델1 파라미터 불러오기\n",
        "# model1_p = torch.load(PATH2, map_location=device)\n",
        "## test 이미지파일 전처리, 텐서화\n",
        "# import torchvision\n",
        "# from torchvision import transforms\n",
        "# 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "transforms_test = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "# root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/upload', \n",
        "\t\t\t\t\ttransform = transforms_test)\n",
        "## 확인\n",
        "testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "# rgb three channel 이니까 3\n",
        "# 높이 넓이 600 600 리사이즈\n",
        "# 전처리 정상 완료 확인\n",
        "# DataLoader를 통해 네트워크에 올리기\n",
        "# from torch.utils.data import Dataset,DataLoader \n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "# dataiter = iter(testloader)\n",
        "# images = dataiter.next()\n",
        "# images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "output_list = []\n",
        "model3.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "correct = 0\n",
        "# 로스 연산\n",
        "# import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "# test_loss = 0\n",
        "# from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "            for data, target in tqdm(testloader):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model3(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                output_list.append(output);\n",
        "                # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "# test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "# 로스, 아큐러시 출력\n",
        "# print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "# 업로드 이미지에 대한 output predict 값\n",
        "# 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "#  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "m3output = output_list[-1]\n",
        "m3predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "print()\n",
        "print()\n",
        "print('model3 모낭사이홍반 output :', m3output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "print('model3 모낭사이홍반 predict :',m3predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "# 모델4 upload file predict\n",
        " \n",
        "# 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "# PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "# model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "# testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "# model1.eval()\n",
        "# output = model1(data) \n",
        "\n",
        "# 구글드라이브 마운트\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')  \n",
        "# 모델.pt파일 경로\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model4.pt'  # 모델1\n",
        "# PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "# CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "# import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델1 불러오기\n",
        "# !pip install efficientnet_pytorch\n",
        "model4 = torch.load(PATH, map_location=device)\n",
        "# 모델1 파라미터 불러오기\n",
        "# model1_p = torch.load(PATH2, map_location=device)\n",
        "## test 이미지파일 전처리, 텐서화\n",
        "# import torchvision\n",
        "# from torchvision import transforms\n",
        "# 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "transforms_test = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "# root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/upload', \n",
        "\t\t\t\t\ttransform = transforms_test)\n",
        "## 확인\n",
        "testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "# rgb three channel 이니까 3\n",
        "# 높이 넓이 600 600 리사이즈\n",
        "# 전처리 정상 완료 확인\n",
        "# DataLoader를 통해 네트워크에 올리기\n",
        "# from torch.utils.data import Dataset,DataLoader \n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "# dataiter = iter(testloader)\n",
        "# images = dataiter.next()\n",
        "# images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "output_list = []\n",
        "model4.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "correct = 0\n",
        "# 로스 연산\n",
        "# import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "# test_loss = 0\n",
        "# from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "            for data, target in tqdm(testloader):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model4(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                output_list.append(output);\n",
        "                # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "# test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "# 로스, 아큐러시 출력\n",
        "# print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "# 업로드 이미지에 대한 output predict 값\n",
        "# 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "#  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "m4output = output_list[-1]\n",
        "m4predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "print()\n",
        "print()\n",
        "print('model4 모낭홍반농포 output :', m4output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "print('model4 모낭홍반농포 predict :',m4predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "# 모델5 upload file predict\n",
        " \n",
        "# 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "# PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "# model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "# testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "# model1.eval()\n",
        "# output = model1(data) \n",
        "\n",
        "# 구글드라이브 마운트\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')  \n",
        "# 모델.pt파일 경로\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model5.pt'  # 모델1\n",
        "# PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "# CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "# import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델1 불러오기\n",
        "# !pip install efficientnet_pytorch\n",
        "model5 = torch.load(PATH, map_location=device)\n",
        "# 모델1 파라미터 불러오기\n",
        "# model1_p = torch.load(PATH2, map_location=device)\n",
        "## test 이미지파일 전처리, 텐서화\n",
        "# import torchvision\n",
        "# from torchvision import transforms\n",
        "# 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "transforms_test = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "# root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/upload', \n",
        "\t\t\t\t\ttransform = transforms_test)\n",
        "## 확인\n",
        "testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "# rgb three channel 이니까 3\n",
        "# 높이 넓이 600 600 리사이즈\n",
        "# 전처리 정상 완료 확인\n",
        "# DataLoader를 통해 네트워크에 올리기\n",
        "# from torch.utils.data import Dataset,DataLoader \n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "# dataiter = iter(testloader)\n",
        "# images = dataiter.next()\n",
        "# images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "output_list = []\n",
        "model5.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "correct = 0\n",
        "# 로스 연산\n",
        "# import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "# test_loss = 0\n",
        "# from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "            for data, target in tqdm(testloader):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model5(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                output_list.append(output);\n",
        "                # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "# test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "# 로스, 아큐러시 출력\n",
        "# print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "# 업로드 이미지에 대한 output predict 값\n",
        "# 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "#  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "m5output = output_list[-1]\n",
        "m5predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "print()\n",
        "print()\n",
        "print('model5 비듬 output :', m5output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "print('model5 비듬 predict :',m5predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "# 모델6 upload file predict\n",
        " \n",
        "# 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "# PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "# model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "# testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "# model1.eval()\n",
        "# output = model1(data) \n",
        "\n",
        "# 구글드라이브 마운트\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')  \n",
        "# 모델.pt파일 경로\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model6.pt'  # 모델1\n",
        "# PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "# CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "# import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델1 불러오기\n",
        "# !pip install efficientnet_pytorch\n",
        "model6 = torch.load(PATH, map_location=device)\n",
        "# 모델1 파라미터 불러오기\n",
        "# model1_p = torch.load(PATH2, map_location=device)\n",
        "## test 이미지파일 전처리, 텐서화\n",
        "# import torchvision\n",
        "# from torchvision import transforms\n",
        "# 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "transforms_test = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "# root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/upload', \n",
        "\t\t\t\t\ttransform = transforms_test)\n",
        "## 확인\n",
        "testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "# rgb three channel 이니까 3\n",
        "# 높이 넓이 600 600 리사이즈\n",
        "# 전처리 정상 완료 확인\n",
        "# DataLoader를 통해 네트워크에 올리기\n",
        "# from torch.utils.data import Dataset,DataLoader \n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "# dataiter = iter(testloader)\n",
        "# images = dataiter.next()\n",
        "# images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "output_list = []\n",
        "model6.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "correct = 0\n",
        "# 로스 연산\n",
        "# import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "# test_loss = 0\n",
        "# from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "            for data, target in tqdm(testloader):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model6(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                output_list.append(output);\n",
        "                # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "             #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "# test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "# 로스, 아큐러시 출력\n",
        "# print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "# 업로드 이미지에 대한 output predict 값\n",
        "# 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "#  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "m6output = output_list[-1]\n",
        "m6predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "print()\n",
        "print()\n",
        "print('model6 탈모 output :', m6output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "print('model6 탈모 predict :',m6predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "# 진단\n",
        "\n",
        "m1p = m1predict[0][0].tolist()\n",
        "m2p = m2predict[0][0].tolist() \n",
        "m3p = m3predict[0][0].tolist()  \n",
        "m4p = m4predict[0][0].tolist() \n",
        "m5p = m5predict[0][0].tolist() \n",
        "m6p = m6predict[0][0].tolist()\n",
        "\n",
        "if m1p == 0 and m2p == 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "    print('정상입니다.')\n",
        "\n",
        "elif m1p != 0 and m2p == 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "    print('건성 두피입니다.')\n",
        "\n",
        "elif m1p == 0 and m2p != 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "    print('지성 두피입니다.')\n",
        "\n",
        "elif m2p == 0 and m3p != 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "    print('민감성 두피입니다.')\n",
        "\n",
        "elif m2p != 0 and m3p != 0 and m4p == 0 and m6p == 0 :\n",
        "    print('지루성 두피입니다.')\n",
        "\n",
        "elif m3p == 0 and m4p != 0 and m6p == 0 :\n",
        "    print('염증성 두피입니다.')\n",
        "\n",
        "elif m3p == 0 and m4p == 0 and m5p != 0 and m6p == 0 :\n",
        "    print('비듬성 두피입니다.')\n",
        "\n",
        "elif m1p == 0 and m2p != 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p != 0 :\n",
        "    print('탈모입니다.')\n",
        "else:\n",
        "    print('복합성 두피입니다.')\n",
        "print()\n",
        "\n",
        "print('0:양호, 1:경증, 2:중등도, 3:중증',end='\\n\\n')\n",
        "print('미세각질 :',m1p )\n",
        "print('피지과다 :',m2p ) \n",
        "print('모낭사이홍반 :',m3p )  \n",
        "print('모낭홍반농포 :',m4p ) \n",
        "print('비듬 :',m5p ) \n",
        "print('탈모 :',m6p ) "
      ],
      "metadata": {
        "id": "i_IW7yDkIhHj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}