{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "okt, CountVectorizer",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "okt"
      ],
      "metadata": {
        "id": "ScKbFZYCPmWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장처리 (각 단어 빈도), tk.morphs(입력문자) #쪼개기 \n",
        "! pip install kss konlpy\n",
        "import nltk, kss, konlpy\n",
        "from konlpy.tag import Okt # 한국어 단어 토크나이저\n",
        "t_data = '나는 오늘은 습기가 높아서 슬퍼 강의는 잘 듣고 있니?'\n",
        "tk = Okt()\n",
        "tk.morphs(t_data)\n",
        "def 문장_처리(in_t):\n",
        "    입력문자 = in_t.replace('?','') #물음표제거\n",
        "    토큰_data= tk.morphs(입력문자) #쪼개기     \n",
        "    단어집합 = {}    #보캐만들기\n",
        "    단어빈도수 = []\n",
        "    for 단어 in 토큰_data:\n",
        "        if 단어 not in 단어집합 : #단어집합 딕셔너리에 없다면 # 딕셔너리에키값으로\n",
        "            단어집합[단어] = len(단어집합)  # 키와밸류 추가 # len(단어집합)부터 연산하니까 0이 들어감 즉 0부터 순서값\n",
        "            단어빈도수.insert(len(단어집합)-1 , 1) # insert    # 1:처음들어가니까  #  len(단어집합)-1인덱스의 값에 +1을 한다는 뜻 # 여기서는 하나들어갔으니까 1-1 >0인덱스에 +1\n",
        "        else:\n",
        "            단어인덱스 = 단어집합.get(단어)  # 단어의 인덱스 # get 밸류뽑아오는\n",
        "            단어빈도수[단어인덱스] += 1 #횟수 기록\n",
        "    return 단어집합, 단어빈도수 #튜플로 두개 리턴\n",
        "문장_처리(t_data) # 는 > 1인덱스 > 두번째 리스트에서 1인덱스에 숫자2  는 이게 2번 나왔다는 뜻"
      ],
      "metadata": {
        "id": "2iOhvOm9PoY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer"
      ],
      "metadata": {
        "id": "TRSP2IhhPo7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 트랜스폼, 보캐불러리, 디티엠\n",
        "t_data = '나는 오늘은 습기가 높아서 슬퍼 강의는 잘 듣고 있니?'\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "t_t = t_data.replace('?','')\n",
        "bv = CountVectorizer()\n",
        "bv.fit_transform([t_t]).toarray()\n",
        "bv.vocabulary_ #보캐 : 단어별 인덱\n",
        "문서 = [ '나는 강의는 어려워', '나는 날씨가 덥고 습기가 많아', '나는 오늘은 그냥 있니?' , '나는 수업은 듣고 있니?' ]\n",
        "# DTM 행렬 / BOW빈도\n",
        "bv.transform(문서).toarray()\n",
        "bv2.vocabulary_\n",
        "bv2 = CountVectorizer(stop_words=['나는']) #불용어=나는\n",
        "bv2.fit_transform(문서).toarray()\n",
        "bv2.vocabulary_ # '나는'이 없다"
      ],
      "metadata": {
        "id": "4FeHS9ELPrWz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}