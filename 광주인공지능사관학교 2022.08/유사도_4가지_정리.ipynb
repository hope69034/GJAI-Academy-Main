{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "유사도_4가지_정리",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "유사도"
      ],
      "metadata": {
        "id": "a92zJIyxJOcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 코사인 유사도 (-1 ~ +1), 커야 유사도가 높다, 두 벡터 간 코사인 각도, 방향2성, 코사인0도 = +1 동일한 방향\n",
        "2. 자카드 유사도 (0 ~ +1), 커야 유사도가 높다, 공식: 두 A,B에 대하여 교집합/합집합, 즉 동일하다면 +1\n",
        "3. 유클리드 유사도 (0~x), 작아야 유사도가 높다, 벡터화된 두 점의 거리를 피타고라스 정리를 통해 구한다\n",
        "4. 멘하탄 유사도 (0~x), 작아야 유사도가 높다, 사각형 격자 지도를 따라갈 수 있는 최단거리"
      ],
      "metadata": {
        "id": "8Rld76EmJPkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 코사인 유사도"
      ],
      "metadata": {
        "id": "_gS-MiZlJQA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 코사인 유사도 (-1 ~ +1), 커야 유사도가 높다, 두 벡터 간 코사인 각도, 방향2성, 코사인0도 = +1 동일한 방향\n",
        "\n",
        "# 코사인 유사도 공식을 def로 선언하여 연산하기\n",
        "\n",
        "# 불러오기    # [ eq.wqe.ewq ]한문장이 하나의 벡터 하나의 점-원점 선의 방향\n",
        "import numpy as np\n",
        "# 스칼라 점 값 < 스칼라의합 벡터 1차원 <  행렬 매트릭스 2차원 행렬 <  3차원부터 텐서\n",
        "data1 = np.array([1,1,1,1]) # 벡터 데이터 = 1차원 어레이 # 데이터관점에서는 4차원이다 데이터관점에서는 피처수가 차원\n",
        "# np.linalg.norm(data1) # 코사인유사도 공식에서 l  l  연산임  # linalg.norm  벡터를 정규화  # 원점에서 점으로 선 긋기\n",
        "# 공식 분자부분 A*B : 벡터 간 곱 > 내적 dot\n",
        "\n",
        "# 코사인 유사도 공식 -1~+1   +1이 유사도가 가장 높다 -1이 낮다\n",
        "def cos_i(A,B): #코사인유사도 # 벡터간기울기비교 방향성이 같은지 유사도 판별  #방향같으면 1 역방향이면 -1   구십도면 0 (긍정방향/부정방향)\n",
        "    return A.dot(B)/(np.linalg.norm(A)*np.linalg.norm(B))\n",
        "\n",
        "# 코사인 유사도 연산 # 1차원리스트 1차원 벡터 두개  벡터 선 두개의 방향성의 유사도를 연산\n",
        "# d1 = np.array( [0,5,5,5])\n",
        "# d2 = np.array( [0,-1,-1,-1])\n",
        "d1 = np.array( [1,1,1,1])\n",
        "d2 = np.array( [2,2,2,2])\n",
        "cos_i(d1,d2) # 값 : -1  각도차 180도 #()안 값이 하나면 에러 "
      ],
      "metadata": {
        "id": "D0urSoDAJQEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코사인 유사도를 cosine_similarity 라이브러리로 측정\n",
        "\n",
        "# 불러오기    # [ eq.wqe.ewq ]한문장이 하나의 벡터 하나의 점-원점 선의 방향\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # TFITF 의 정규화로 벡터라이즈\n",
        "from sklearn.metrics.pairwise import cosine_similarity # 코사인유사도\n",
        "\n",
        "# 데이터\n",
        "data = pd.read_csv('data1.csv', low_memory=False,  ) # 데이터 리드\n",
        "data = data.head(20000) # 20000 줄/인덱 까지 출력 (영화타이틀:숫자)\n",
        "data['overview'] = data['overview'].fillna('') # 결측지를 '' 공백문자로 치환\n",
        "\n",
        "# 벡터라이저 핏\n",
        "tfidf = TfidfVectorizer (stop_words='english') # 스탑워드 불용어  # 문장가져오기\n",
        "tfidf_t = tfidf.fit_transform(data['overview']) # 문장을 가져와서 (1차원벡터리스트) 핏_트랜스폼 # 15507개 data니까 자기자신과 15506개의 다른 data의 유사도를 연산할 수 있다 자기자신포함 15507 개의 유사도를 가질 수 있다\n",
        "tfidf_t\n",
        "\n",
        "# 벡터화된 데이터로 코사인유사도 측정하는 cos 변수 선언\n",
        "cos = cosine_similarity(tfidf_t, tfidf_t) # 이만개의 유사도를 가진 것이 이만개니까 # 이만*이만 개의 유사도 # 유사도가 높은 순서로 정렬이된다\n",
        "cos.shape # (이만,이만)  #오버뷰를 TFIDF정규화벡터화한 것 간의 유사도 측정\n",
        "\n",
        "# 영화타이틀 데이터 전처리\n",
        "data.index # 이만개의 인덱\n",
        "t_idx = dict(zip(data['title'], data.index )) # 집으로 결합해서 딕셔너리화   영화제목 : 인덱스\n",
        "t_idx\n",
        "\n",
        "# 특정 영화의 상위 유사도 뽑기\n",
        "def ck_s_t(t, cosine_sim = cos ):\n",
        "    idx = t_idx[t]  # (영화타이틀과 인덱) 딕셔너리 / 여기서 [타이틀]을 > 딕셔너리에서 키값을 넣었으니 인덱스를 받는다\n",
        "    c_sc = list(enumerate(cosine_sim[idx])) # cos는 위에서 이미 정의내려졌다. # (유사도,인덱스) # 그인덱스를 cos로넣으면[ 유사도,유사도,유사도,유사도,유사도...]를 받고 이누머로 인덱스 붙여서 리스트화 # 받은 영화타이틀에 넘버링 #이누머-열거, 각 밸류에 인덱스를 붙여준다  (인덱스,밸류=코사인유사도)\n",
        "    c_sc = sorted ( c_sc, key=lambda a:a[1] , reverse=True) # (인덱스,유사도)로 정렬# sorted정렬하는함수 # 유사도와 이누머인덱스 둘 중 1인덱값(이누머인덱)을 키로해서 정렬한다 # 인덱이 앞으로온다  (인덱:유사도)\n",
        "    return c_sc  #  (인덱,유사도) 를 리턴 # c_sc에는 유사도가 높은 순서로 정렬되어있다. \n",
        "ck_s_t('Toy Story')[0] # 유사도가장높은것 (자기자신)\n",
        "ck_s_t('Toy Story')[0:5] # 유사도 상위 5위 뽑기 # (인덱스,유사도) (15348, 0.5258229300737997), 이렇게 뽑혀서 무슨 영화인지 알아보기 힘들다\n",
        "\n",
        "# 특정 영화의 상위 유사도 영화제목으로 뽑기\n",
        "def ck_s_t(t, cosine_sim = cos ):\n",
        "    idx = t_idx[t]\n",
        "    c_sc = list(enumerate(cosine_sim[idx])) # 넘버링 #이누머-열거\n",
        "    c_sc = sorted ( c_sc, key=lambda x:x[1] , reverse=True) # reverse=True 내림차순 , 코사인유사도는 높은 것이 좋은 거니까, 디폴트는 오름차순\n",
        "    m_d = c_sc[1:6] # (인덱스,유사도) (15348, 0.5258229300737997),  # 0인덱은 자기자신이니까 빼고 상위 1,2,3,4,5 위의 유사도가 높은 것을 뽑는다. \n",
        "    m_i = [i[0]for i in m_d]  # (인덱스,유사도) 를 하나 뽑아서 [0]인덱스 > 인덱스 뽑아서 리스트로 >  상위 5위까지 인덱스를 뽑았다\n",
        "    return data['title'].iloc[m_i] #영화타이틀 시리즈에서 그 인덱 값들만 뽑아온다 (판다스시리즈 타입으로 뽑힌다)\n",
        "pd.DataFrame(ck_s_t('Toy Story'))"
      ],
      "metadata": {
        "id": "0yfLrnSHJQIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 자카드 유사도"
      ],
      "metadata": {
        "id": "k6zP-lO2JQMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 자카드 유사도 (0 ~ +1), 커야 유사도가 높다, 공식: 두 A,B에 대하여 교집합/합집합, 즉 동일하다면 +1\n",
        "\n",
        "# 자카드 유사도 기본 : len(교집합)/len(합집합) # [ eq.wqe.ewq ]한문장이 하나의 벡터 하나의 점-원점 선의 방향\n",
        "\n",
        "# 교집합과 합집합\n",
        "A = set([1,2,3,4,5]) # set 중복제거\n",
        "B = set([4,5,6,7,8,9])\n",
        "A&B  # and  교집합\n",
        "A|B  # or   합집합\n",
        "\n",
        "# 여러 문장을 자카드 유사도로\n",
        "data1 = '나는 오늘 정말 피곤해 그래서 힘들어'.split()\n",
        "data2 = '나는 오늘 정말 못해 그래서 힘들어'.split()\n",
        "data3 = '나는 오늘 너무 즐거와 그래서 행복해'.split()\n",
        "data1\n",
        "intd = set(data1) & set(data2) # 교집합\n",
        "intd\n",
        "un = set(data1) | set(data2) # 합집합\n",
        "un\n",
        "len(intd)/len(un) # data1과 dat2의 자카드 유사도 : 0.7\n",
        "un1=set(data1) | set(data3)\n",
        "intd1=set(data1) & set(data3)\n",
        "len(intd1)/len(un1) # 0.3  # data1은 data3보다 data2와 더 유사도가 높다"
      ],
      "metadata": {
        "id": "BFnUgIkHJQP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 유클리드 유사도"
      ],
      "metadata": {
        "id": "uC2zLVaRJQTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 유클리드 유사도 (0~x), 작아야 유사도가 높다, 벡터화된 두 점의 거리를 피타고라스 정리를 통해 구한다\n",
        "\n",
        "# 피타고라스 정리를 def로 선언하여 연산하는 유클리드 유사도\n",
        "\n",
        "data1 = '나는 오늘 정말 피곤해 그래서 힘들어'    # [ eq.wqe.ewq ]한문장이 하나의 벡터 하나의 점-원점 선의 방향\n",
        "data2 = '나는 오늘 정말 못해 그래서 힘들어' \n",
        "data3 = '나는 오늘 너무 즐거와 그래서 행복해' \n",
        "t_v = TfidfVectorizer()\n",
        "m_data = t_v.fit_transform( [data1,data2,data3] ) # 각각의 문장들로 점 3개가 만들어졌다.\n",
        "a = m_data.toarray() # 각각의 문장들로 점 3개가 만들어졌다.\n",
        "pd.DataFrame(a)\n",
        "\n",
        "# 피타고라스 정리로 두 점의 거리 계산\n",
        "def f(A,B):\n",
        "    return np.sqrt( np.sum((A-B)**2)  ) #  뺴기제곱+빼기제곱에 루트 : 피타고라스정리로 A,B간의 거리를 구한다\n",
        "    \n",
        "A = m_data.toarray()[0] #하나의문장으로뽑음 (벡터)  3개의 점\n",
        "B = m_data.toarray()[1] #하나의문장으로뽑음 (벡터)\n",
        "C = m_data.toarray()[2] #하나의문장으로뽑음 (벡터)\n",
        "\n",
        "f(A,B), f(A,C)  \n",
        "\n",
        "# A는 C와 더 유사하다 # 벡터라이저를 기반으로 뽑았기 때문에 정규화가 필요하다\n",
        "# > 정규화작업\n",
        "def e_f(m):\n",
        "    return m/np.sum(m)\n",
        "e_f(m_data) #정규화끝난매트릭스데이터\n",
        "e_b_d = e_f(m_data)\n",
        "print(e_b_d)"
      ],
      "metadata": {
        "id": "JgBesUojJQXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#유클리드 유사도 라이브러리 사용\n",
        "\n",
        "from sklearn.metrics import euclidean_distances #유클리드거리 소문자-매소드\n",
        "# m_data 벡터화된 숫자 데이터\n",
        "euclidean_distances(m_data[0:1], m_data[1:2]) #거리값 # 각 벡터화된 문장을 넣어줌\n",
        "# e_b_d 는 m_data의 > 유클리드유사도 > 정규화\n",
        "euclidean_distances(e_m_d[0:1], e_m_d[1:2])"
      ],
      "metadata": {
        "id": "nZzFE4BdJQbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 멘하탄 유사도"
      ],
      "metadata": {
        "id": "HU53hGUIJQfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 멘하탄 유사도 (0~x), 작아야 유사도가 높다, 사각형 격자 지도를 따라갈 수 있는 최단거리\n",
        "\n",
        "# 멘하탄 유사도 라이브러리를 활용\n",
        "\n",
        "from sklearn.metrics.pairwise import manhattan_distances\n",
        "print( manhattan_distances(m_data[0:1], m_data[1:2])  , manhattan_distances(m_data[0:1], m_data[2:])  )\n",
        "print( manhattan_distances(e_m_d[0:1], e_m_d[1:2])  ,manhattan_distances(m_data[0:1], m_data[2:])     )"
      ],
      "metadata": {
        "id": "iVuAJPOMJj9x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}