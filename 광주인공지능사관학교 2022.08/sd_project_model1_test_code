{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sd_project_m1_test_code",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 구글드라이브 마운트\n",
        "!pip install flask-ngrok > /dev/null 2>&1\n",
        "!pip install pyngrok > /dev/null 2>&1\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('drive/MyDrive/Colab Notebooks/project/static/ngrok_auth.txt') as nf:\n",
        "    ngrok_auth = nf.read()\n",
        "\n",
        "!ngrok authtoken $ngrok_auth\n",
        "\n",
        "from flask import Flask, render_template, request, current_app\n",
        "import os\n",
        "\n",
        "from flask_ngrok import run_with_ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kynxm5PGU_xb",
        "outputId": "2acbaab8-4335-4187-951d-a72809708995"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import copy\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from efficientnet_pytorch import EfficientNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUPqiJSqlJZ3",
        "outputId": "0da85b78-10bb-4085-889f-6204c90aee93"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (4.1.1)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=ade0cd94b1cd33b3ec7c43af98b5ced7b8120f5550e9e981545925cdd9dc03b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델.pt파일 경로\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # 모델1\n",
        "PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터"
      ],
      "metadata": {
        "id": "x89sNPP1W7Hq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "CGwLdalBzw7U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델1 불러오기\n",
        "model1 = torch.load(PATH, map_location=device)"
      ],
      "metadata": {
        "id": "CA6b7Q3pXg9N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델1 파라미터 불러오기\n",
        "# model1_p = torch.load(PATH2, map_location=device)"
      ],
      "metadata": {
        "id": "FOBzDrrsX2TX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## test 이미지파일 전처리, 텐서화\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# 전처리-트랜스폼 규칙 선언 # validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "transforms_test = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "\n",
        "# root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test', \n",
        "\t\t\t\t\ttransform = transforms_test)"
      ],
      "metadata": {
        "id": "yPT0RlEyhrBw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 확인\n",
        "testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "# rgb three channel 이니까 3\n",
        "# 높이 넓이 600 600 리사이즈\n",
        "# 전처리 정상 완료 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGcM_qgwjMLr",
        "outputId": "128dc57d-f33e-460b-d26c-dc5f4599929a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 600, 600])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader를 통해 네트워크에 올리기 \n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "# dataiter = iter(testloader)\n",
        "# images = dataiter.next()\n",
        "# images[0].shape # 처음1은 배치사이즈와 동일"
      ],
      "metadata": {
        "id": "W6Gk1e7nHddo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "\n",
        "output_list = []\n",
        "model1.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "correct = 0\n",
        "#test_loss = 0\n",
        "#import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "\n",
        "with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "        for data, target in testloader:                                    \n",
        "            data, target  = data.to(device), target.to(device) \n",
        "            output = model1(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "            output_list.append(output);\n",
        "            #test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "            pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1\n",
        "            #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "#test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset))) #축적된 예측값을 데이터 개수로 나누기 *100 확률%값\n",
        "\n",
        "# 로스, 아큐러시 출력\n",
        "#print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K14_uqzGGU7X",
        "outputId": "107b1b61-0dd7-4698-b8ac-b51235418d75"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set Accuracy: 450/1084 (41.5129%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아큐러시 측정 방법\n",
        "\n",
        "# test0 pred    Test set Accuracy: 2/35 (5.7143%) # 아웃풋 확인 결과 실제로 0 을 두개 맞춤 / 정답을 어떻게 알고 채점을 하지?\n",
        "# test1 pred    확인 결과 폴더가 하나 있으면 정답을 무조건 0 으로 하여 아큐러시를 도출함"
      ],
      "metadata": {
        "id": "e8NYGVtbuh0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 하나 정답 아웃풋 predict 확인\n",
        "# output_list[0].argmax(dim=1, keepdim=True) \n",
        "# 최근 업로드 파일, -1인덱스로 ?\n",
        "# output_list[-1].argmax(dim=1, keepdim=True)  # output_list[-1] 은 각 0 1 2 3 의 값 > argmax로 최댓값의 인덱스를 리턴\n",
        "# 즉 테스트 폴더를 업로드 경로로 지정하여 결과를 리턴\n",
        "output_list[-1] , output_list[-1].argmax(dim=1, keepdim=True) # 각 0 1 2 3 갑 중 가장 높은 인덱스는 2 >  2 를 predict 함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlJFpREe5HMz",
        "outputId": "5112ae52-7eb3-40c5-95f8-fe866dcf484f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0'),\n",
              " tensor([[2]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}
