{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_23.sd.project.front.end.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Template App - Run with Ngrok and Colab"
      ],
      "metadata": {
        "id": "gaKdMwRc-uJo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Czut_Fdx-qO5"
      },
      "outputs": [],
      "source": [
        "!pip install flask-ngrok > /dev/null 2>&1\n",
        "!pip install pyngrok > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgCMECiH-6bI",
        "outputId": "da539c83-78b1-426c-8b2b-cc94bac81151"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('drive/MyDrive/project/static/ngrok_auth.txt') as nf:\n",
        "    ngrok_auth = nf.read()"
      ],
      "metadata": {
        "id": "n-u2Q4dr_U8f"
      },
      "execution_count": 3,
      
      
      
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2DhgO5MjhmZSX4JI2hjppxKaiyA_29rMtfrrptS3nr3YkTXbd\n",
        "!cat drive/MyDrive/project/static/ngrok_auth.txt "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv-KIwm9qcFR",
        "outputId": "c58a0c78-d7ac-4e3a-ad65-33ac629e0e79"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2DhhM4zGyNGOWbPiOdKqnZOPYWi_2YmSF58Pc5289ZMLH5j3m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken $ngrok_auth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvxYjmh4AMhA",
        "outputId": "9d4a976c-ae88-4b25-d0a7-0d4351a46619"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXgf460kvoWA",
        "outputId": "5d19fb5e-dd76-4246-f744-69d9805c3639"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (4.1.1)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=9eb0e6caf2a2e45ba1f7f5bceda2f794cfe877f1e725c42051e1688f589b4473\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web Server Code"
      ],
      "metadata": {
        "id": "rMAfkvTsAZ0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import os\n",
        "\n",
        "app = Flask(__name__, static_folder='/content/drive/MyDrive/project/static/upload', # 이곳에 유저가 업로드한 파일을 save\n",
        "                      template_folder='/content/drive/MyDrive/project/templates')\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    menu = {'home':1, 'menu':0}\n",
        "    return render_template('index.html', menu=menu)\n",
        "\n",
        "@app.route('/menu', methods=['GET','POST'])\n",
        "def menu():\n",
        "    menu = {'home':0, 'menu':1}\n",
        "    if request.method == 'GET':\n",
        "        languages = [\n",
        "            #{'disp':'영어', 'val':'en'},\n",
        "            #{'disp':'일어', 'val':'jp'},\n",
        "            #{'disp':'중국어', 'val':'cn'},\n",
        "            #{'disp':'프랑스어', 'val':'fr'},\n",
        "            #{'disp':'스페인어', 'val':'es'}\n",
        "        ]\n",
        "        \n",
        "        return render_template('menu.html', menu=menu,\n",
        "                                options=languages)   # 서버에서 클라이언트로 정보 전달\n",
        "    else:\n",
        "        # 사용자가 입력한 정보를 서버가 읽음\n",
        "        # index = request.form['index']\n",
        "        # lang = request.form['lang']\n",
        "        # lyrics = request.form['lyrics']\n",
        "        #print(lang, '\\n', index, '\\n', lyrics, sep='')\n",
        "        # 사용자가 입력한 파일을 읽어서 upload 디렉토리에 저장\n",
        "        f_image = request.files['image']\n",
        "        fname = f_image.filename                # 사용자가 입력한 파일 이름\n",
        "        filename = os.path.join(app.static_folder, 'upload/') + fname  # 유저가 업로드한 사진이 저장되는 공간과 파일이름 \n",
        "                                        # static_folder/upload 가 경로 파일네임 : fname 유저가 업로드한 파일의 이름 \n",
        "        f_image.save(filename) #파일세이브\n",
        "       \n",
        "\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "\n",
        "     \n",
        "        PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # 모델1\n",
        "        # PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "        # CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "        import torch\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # 모델1 불러오기\n",
        "        model1 = torch.load(PATH, map_location=device)\n",
        "        # 모델1 파라미터 불러오기\n",
        "        # model1_p = torch.load(PATH2, map_location=device)\n",
        "        ## test 이미지파일 전처리, 텐서화\n",
        "        \n",
        "        # 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "        transforms_test = transforms.Compose([\n",
        "                                                transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                            ])\n",
        "        # root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "        testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/project/static/upload' ,\n",
        "                            transform = transforms_test)\n",
        "        ## 확인\n",
        "        testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "        # rgb three channel 이니까 3\n",
        "        # 높이 넓이 600 600 리사이즈\n",
        "        # 전처리 정상 완료 확인\n",
        "        # DataLoader를 통해 네트워크에 올리기\n",
        "        from torch.utils.data import Dataset,DataLoader \n",
        "        testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "        # dataiter = iter(testloader)\n",
        "        # images = dataiter.next()\n",
        "        # images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "        ## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "        output_list = []\n",
        "        model1.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "        correct = 0\n",
        "        # 로스 연산\n",
        "        # import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "        # test_loss = 0\n",
        "        from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "        if __name__ == '__main__':\n",
        "            with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "                    for data, target in tqdm(testloader):                                   \n",
        "                        data, target  = data.to(device), target.to(device) \n",
        "                        output = model1(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                        output_list.append(output)\n",
        "\n",
        "        m1output = output_list[-1]\n",
        "        m1predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "        ## 모델2\n",
        "\n",
        "        PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model2.pt'  # 모델1\n",
        "        # PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "        # CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "        # import torch\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # 모델1 불러오기\n",
        "        # !pip install efficientnet_pytorch\n",
        "        model2 = torch.load(PATH, map_location=device)\n",
        "        # 모델1 파라미터 불러오기\n",
        "        # model1_p = torch.load(PATH2, map_location=device)\n",
        "        ## test 이미지파일 전처리, 텐서화\n",
        "        # import torchvision\n",
        "        # from torchvision import transforms\n",
        "        # 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "        transforms_test = transforms.Compose([\n",
        "                                                transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                            ])\n",
        "        # root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "        testset = torchvision.datasets.ImageFolder(root =  '/content/drive/MyDrive/project/static/upload', \n",
        "                            transform = transforms_test)\n",
        "        ## 확인\n",
        "        testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "        # rgb three channel 이니까 3\n",
        "        # 높이 넓이 600 600 리사이즈\n",
        "        # 전처리 정상 완료 확인\n",
        "        # DataLoader를 통해 네트워크에 올리기\n",
        "        # from torch.utils.data import Dataset,DataLoader \n",
        "        testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "        # dataiter = iter(testloader)\n",
        "        # images = dataiter.next()\n",
        "        # images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "        ## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "        output_list = []\n",
        "        model2.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "        correct = 0\n",
        "        # 로스 연산\n",
        "        # import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "        # test_loss = 0\n",
        "        # from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "        if __name__ == '__main__':\n",
        "            with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "                    for data, target in tqdm(testloader):                                   \n",
        "                        data, target  = data.to(device), target.to(device) \n",
        "                        output = model2(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                        output_list.append(output);\n",
        "                        # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                        # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                        # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "        # test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "        # 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "        # print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "        # 로스, 아큐러시 출력\n",
        "        # print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "        # 업로드 이미지에 대한 output predict 값\n",
        "        # 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "        #  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "        m2output = output_list[-1]\n",
        "        m2predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "        #print()\n",
        "        #print()\n",
        "        #print('model2 피지과다 output :', m2output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "        #print('model2 피지과다 predict :',m2predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "        # 모델3 upload file predict\n",
        "        \n",
        "        # 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "        # PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "        # model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "        # testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "        # model1.eval()\n",
        "        # output = model1(data) \n",
        "\n",
        "        # 구글드라이브 마운트\n",
        "        # from google.colab import drive\n",
        "        # drive.mount('/content/drive')  \n",
        "        # 모델.pt파일 경로\n",
        "        PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model3.pt'  # 모델1\n",
        "        # PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "        # CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "        # import torch\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # 모델1 불러오기\n",
        "        # !pip install efficientnet_pytorch\n",
        "        model3 = torch.load(PATH, map_location=device)\n",
        "        # 모델1 파라미터 불러오기\n",
        "        # model1_p = torch.load(PATH2, map_location=device)\n",
        "        ## test 이미지파일 전처리, 텐서화\n",
        "        # import torchvision\n",
        "        # from torchvision import transforms\n",
        "        # 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "        transforms_test = transforms.Compose([\n",
        "                                                transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                            ])\n",
        "        # root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "        testset = torchvision.datasets.ImageFolder(root =  '/content/drive/MyDrive/project/static/upload',  \n",
        "                            transform = transforms_test)\n",
        "        ## 확인\n",
        "        testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "        # rgb three channel 이니까 3\n",
        "        # 높이 넓이 600 600 리사이즈\n",
        "        # 전처리 정상 완료 확인\n",
        "        # DataLoader를 통해 네트워크에 올리기\n",
        "        # from torch.utils.data import Dataset,DataLoader \n",
        "        testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "        # dataiter = iter(testloader)\n",
        "        # images = dataiter.next()\n",
        "        # images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "        ## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "        output_list = []\n",
        "        model3.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "        correct = 0\n",
        "        # 로스 연산\n",
        "        # import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "        # test_loss = 0\n",
        "        # from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "        if __name__ == '__main__':\n",
        "            with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "                    for data, target in tqdm(testloader):                                   \n",
        "                        data, target  = data.to(device), target.to(device) \n",
        "                        output = model3(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                        output_list.append(output);\n",
        "                        # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                        # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                        # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "        # test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "        # 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "        # print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "        # 로스, 아큐러시 출력\n",
        "        # print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "        # 업로드 이미지에 대한 output predict 값\n",
        "        # 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "        #  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "        m3output = output_list[-1]\n",
        "        m3predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "        #print()\n",
        "        #print()\n",
        "        #print('model3 모낭사이홍반 output :', m3output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "        #print('model3 모낭사이홍반 predict :',m3predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "        # 모델4 upload file predict\n",
        "        \n",
        "        # 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "        # PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "        # model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "        # testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "        # model1.eval()\n",
        "        # output = model1(data) \n",
        "\n",
        "        # 구글드라이브 마운트\n",
        "        # from google.colab import drive\n",
        "        # drive.mount('/content/drive')  \n",
        "        # 모델.pt파일 경로\n",
        "        PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model4.pt'  # 모델1\n",
        "        # PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "        # CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "        # import torch\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # 모델1 불러오기\n",
        "        # !pip install efficientnet_pytorch\n",
        "        model4 = torch.load(PATH, map_location=device)\n",
        "        # 모델1 파라미터 불러오기\n",
        "        # model1_p = torch.load(PATH2, map_location=device)\n",
        "        ## test 이미지파일 전처리, 텐서화\n",
        "        # import torchvision\n",
        "        # from torchvision import transforms\n",
        "        # 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "        transforms_test = transforms.Compose([\n",
        "                                                transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                            ])\n",
        "        # root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "        testset = torchvision.datasets.ImageFolder(root =  '/content/drive/MyDrive/project/static/upload',  \n",
        "                            transform = transforms_test)\n",
        "        ## 확인\n",
        "        testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "        # rgb three channel 이니까 3\n",
        "        # 높이 넓이 600 600 리사이즈\n",
        "        # 전처리 정상 완료 확인\n",
        "        # DataLoader를 통해 네트워크에 올리기\n",
        "        # from torch.utils.data import Dataset,DataLoader \n",
        "        testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "        # dataiter = iter(testloader)\n",
        "        # images = dataiter.next()\n",
        "        # images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "        ## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "        output_list = []\n",
        "        model4.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "        correct = 0\n",
        "        # 로스 연산\n",
        "        # import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "        # test_loss = 0\n",
        "        # from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "        if __name__ == '__main__':\n",
        "            with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "                    for data, target in tqdm(testloader):                                   \n",
        "                        data, target  = data.to(device), target.to(device) \n",
        "                        output = model4(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                        output_list.append(output);\n",
        "                        # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                        # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                        # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "        # test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "        # 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "        # print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "        # 로스, 아큐러시 출력\n",
        "        # print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "        # 업로드 이미지에 대한 output predict 값\n",
        "        # 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "        #  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "        m4output = output_list[-1]\n",
        "        m4predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "        #print()\n",
        "        #print()\n",
        "        #print('model4 모낭홍반농포 output :', m4output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "        #print('model4 모낭홍반농포 predict :',m4predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "        # 모델5 upload file predict\n",
        "        \n",
        "        # 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "        # PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "        # model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "        # testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "        # model1.eval()\n",
        "        # output = model1(data) \n",
        "\n",
        "        # 구글드라이브 마운트\n",
        "        # from google.colab import drive\n",
        "        # drive.mount('/content/drive')  \n",
        "        # 모델.pt파일 경로\n",
        "        PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model5.pt'  # 모델1\n",
        "        # PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "        # CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "        # import torch\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # 모델1 불러오기\n",
        "        # !pip install efficientnet_pytorch\n",
        "        model5 = torch.load(PATH, map_location=device)\n",
        "        # 모델1 파라미터 불러오기\n",
        "        # model1_p = torch.load(PATH2, map_location=device)\n",
        "        ## test 이미지파일 전처리, 텐서화\n",
        "        # import torchvision\n",
        "        # from torchvision import transforms\n",
        "        # 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "        transforms_test = transforms.Compose([\n",
        "                                                transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                            ])\n",
        "        # root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "        testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/project/static/upload',  \n",
        "                            transform = transforms_test)\n",
        "        ## 확인\n",
        "        testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "        # rgb three channel 이니까 3\n",
        "        # 높이 넓이 600 600 리사이즈\n",
        "        # 전처리 정상 완료 확인\n",
        "        # DataLoader를 통해 네트워크에 올리기\n",
        "        # from torch.utils.data import Dataset,DataLoader \n",
        "        testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "        # dataiter = iter(testloader)\n",
        "        # images = dataiter.next()\n",
        "        # images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "        ## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "        output_list = []\n",
        "        model5.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "        correct = 0\n",
        "        # 로스 연산\n",
        "        # import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "        # test_loss = 0\n",
        "        # from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "        if __name__ == '__main__':\n",
        "            with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "                    for data, target in tqdm(testloader):                                   \n",
        "                        data, target  = data.to(device), target.to(device) \n",
        "                        output = model5(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                        output_list.append(output);\n",
        "                        # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                        # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                        # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "        # test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "        # 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "        # print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "        # 로스, 아큐러시 출력\n",
        "        # print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "        # 업로드 이미지에 대한 output predict 값\n",
        "        # 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "        #  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "        m5output = output_list[-1]\n",
        "        m5predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "        #print()\n",
        "        #print()\n",
        "        #print('model5 비듬 output :', m5output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "        #print('model5 비듬 predict :',m5predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "        # 모델6 upload file predict\n",
        "        \n",
        "        # 모델 2~6 으로 코드 변경시 변경해야 할 것\n",
        "        # PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model1.pt'  # aram_model1.pt 여기서 1 > 2,3,4,5,6\n",
        "        # model1 = torch.load(PATH, map_location=device)   # mode1 > 2,3,4,5,6\n",
        "        # testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Colab Notebooks/train_data/model1/test',    # 여기서 1 > 2,3,4,5,6 (폴더는 학습에서 잡혀있음)\n",
        "        # model1.eval()\n",
        "        # output = model1(data) \n",
        "\n",
        "        # 구글드라이브 마운트\n",
        "        # from google.colab import drive\n",
        "        # drive.mount('/content/drive')  \n",
        "        # 모델.pt파일 경로\n",
        "        PATH = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model6.pt'  # 모델1\n",
        "        # PATH2 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'president_aram_model1.pt' # 모델1 파라미터\n",
        "        # CUDA 를 활용한 GPU 가속 여부에 따라, 장치를 할당 할 수 있도록 변수로 선언\n",
        "        # import torch\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # 모델1 불러오기\n",
        "        # !pip install efficientnet_pytorch\n",
        "        model6 = torch.load(PATH, map_location=device)\n",
        "        # 모델1 파라미터 불러오기\n",
        "        # model1_p = torch.load(PATH2, map_location=device)\n",
        "        ## test 이미지파일 전처리, 텐서화\n",
        "        # import torchvision\n",
        "        # from torchvision import transforms\n",
        "        # 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "        transforms_test = transforms.Compose([\n",
        "                                                transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                            ])\n",
        "        # root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "        testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/project/static/upload',  \n",
        "                            transform = transforms_test)\n",
        "        ## 확인\n",
        "        testset.__getitem__(0)[0].shape  # (0) 테스트셋의 0번째 item\n",
        "        # rgb three channel 이니까 3\n",
        "        # 높이 넓이 600 600 리사이즈\n",
        "        # 전처리 정상 완료 확인\n",
        "        # DataLoader를 통해 네트워크에 올리기\n",
        "        # from torch.utils.data import Dataset,DataLoader \n",
        "        testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "        # dataiter = iter(testloader)\n",
        "        # images = dataiter.next()\n",
        "        # images[0].shape # [1, 3, 600, 600] # 처음1은 배치사이즈와 동일\n",
        "        ## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "        output_list = []\n",
        "        model6.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "        correct = 0\n",
        "        # 로스 연산\n",
        "        # import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "        # test_loss = 0\n",
        "        # from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "        if __name__ == '__main__':\n",
        "            with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "                    for data, target in tqdm(testloader):                                   \n",
        "                        data, target  = data.to(device), target.to(device) \n",
        "                        output = model6(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                        output_list.append(output);\n",
        "                        # test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                        # pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                        # correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다.\n",
        "                    #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "        # test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "        # 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "        # print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "        # 로스, 아큐러시 출력\n",
        "        # print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
        "\n",
        "        # 업로드 이미지에 대한 output predict 값\n",
        "        # 업로드 폴더로 실행 > 아웃풋리스트에서 최근 업로드 파일을 -1인덱스로 잡은 후 아웃풋 리스트에서 -1 인덱스로 최근 업로드 파일을 잡고 argmax로 아웃풋 0 1 2 3 중 최댓값의 인덱스를 리턴\n",
        "\n",
        "        #  0:양호, 1:경증, 2:중등도, 3:중증\n",
        "        m6output = output_list[-1]\n",
        "        m6predict = output_list[-1].argmax(dim=1, keepdim=True)\n",
        "        #print()\n",
        "        #print()\n",
        "        #print('model6 탈모 output :', m6output) # tensor([[-7.3876,  1.1129,  2.3978, -0.7094]], device='cuda:0') 로 각 아웃풋 4개에 대한 수치를 알려줌\n",
        "        #print('model6 탈모 predict :',m6predict)   # 위 값 중 최댓값의 인덱스를 알려줌 > 즉 predict 값\n",
        "\n",
        "\n",
        "        #print()\n",
        "        #print()\n",
        "\n",
        "        # 진단\n",
        "\n",
        "        m1p = m1predict[0][0].tolist()\n",
        "        m2p = m2predict[0][0].tolist() \n",
        "        m3p = m3predict[0][0].tolist()  \n",
        "        m4p = m4predict[0][0].tolist() \n",
        "        m5p = m5predict[0][0].tolist() \n",
        "        m6p = m6predict[0][0].tolist()\n",
        "\n",
        "        d_list = []\n",
        "\n",
        "        if m1p == 0 and m2p == 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "            d1 = '정상입니다.'\n",
        "            d_list.append(d1)\n",
        "        elif m1p != 0 and m2p == 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "            d2 = '건성 두피입니다.'\n",
        "            d_list.append(d2)\n",
        "        elif m1p == 0 and m2p != 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "            d3 = '지성 두피입니다.'\n",
        "            d_list.append(d3)\n",
        "        elif m2p == 0 and m3p != 0 and m4p == 0 and m5p == 0 and m6p == 0 :\n",
        "            d4 = '민감성 두피입니다.'\n",
        "            d_list.append(d4)\n",
        "        elif m2p != 0 and m3p != 0 and m4p == 0 and m6p == 0 :\n",
        "            d5 = '지루성 두피입니다.'\n",
        "            d_list.append(d5)\n",
        "        elif m3p == 0 and m4p != 0 and m6p == 0 :\n",
        "            d6 = '염증성 두피입니다.'\n",
        "            d_list.append(d6)\n",
        "        elif m3p == 0 and m4p == 0 and m5p != 0 and m6p == 0 :\n",
        "            d7 = '비듬성 두피입니다.'\n",
        "            d_list.append(d7)\n",
        "        elif m1p == 0 and m2p != 0 and m3p == 0 and m4p == 0 and m5p == 0 and m6p != 0 :\n",
        "            d8 = '탈모입니다.'\n",
        "            d_list.append(d8)\n",
        "        else:\n",
        "            d9 = '복합성 두피입니다.'\n",
        "            d_list.append(d9)\n",
        "\n",
        "        #print('0:양호, 1:경증, 2:중등도, 3:중증',end='\\n\\n')\n",
        "        #print('미세각질 :',m1p )\n",
        "        #print('피지과다 :',m2p ) \n",
        "        #print('모낭사이홍반 :',m3p )  \n",
        "        #print('모낭홍반농포 :',m4p ) \n",
        "        #print('비듬 :',m5p ) \n",
        "        #print('탈모 :',m6p ) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        "##########################################################################################################################\n",
        " \n",
        "\n",
        "\n",
        "        # 모델 실행후 결과를 돌려줌\n",
        "        \n",
        "        final = d_list[0]\n",
        "        result = {'미세각질':m1p, '피지과다':m2p,'모낭사이홍반':m3p,'모낭홍반농포':m4p,'비듬':m5p,'탈모':m6p}\n",
        "        final2 = '0:양호, 1:경증, 2:중등도, 3:중증'\n",
        "        #result =  d_list, f'''미세각질 : {m1p}, 피지과다 : {m2p}, 모낭사이홍반 : {m3p}, 모낭홍반농포 : {m4p}, 비듬 : {m5p}, 탈모 : {m6p}, (0:양호, 1:경증, 2:중등도, 3:중증)'''\n",
        "        mtime = int(os.stat(filename).st_mtime) # 업로드한 시간값불러오기 > 큐변경 > 화면갱신 \n",
        "        return render_template('menu_res.html', final2=final2,final=final, result=result, menu=menu,\n",
        "                                fname=fname, mtime=mtime)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n",
        "\n",
        "\n",
        "#리절트 > 딕셔너리, vs code갱신\n",
        "# 코드간략화 , 프롬임폴트, 전처리와 프레딕트의 분리, 텐서인풋프레딕트\n",
        "#로고제거\n",
        "# 경우에 따라 결과하면서에서 바로 이미지가 안뜨고 새로고침해야함  > 로딩중화면을띄우기\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jBOBRDAAVE-",
        "outputId": "8aa683d0-eebd-4a6e-8207-80b6c13b83fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://a893-35-184-168-124.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Aug/2022 02:56:02] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Aug/2022 02:56:03] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Aug/2022 02:56:27] \"\u001b[37mGET /menu HTTP/1.1\u001b[0m\" 200 -\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
            "100%|██████████| 1/1 [00:04<00:00,  4.76s/it]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.68s/it]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.59s/it]\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Aug/2022 02:57:30] \"\u001b[37mPOST /menu HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Aug/2022 02:57:31] \"\u001b[37mGET /upload/upload/aa.jpg?q=1661223393 HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YN2VU47UUDEp"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}
