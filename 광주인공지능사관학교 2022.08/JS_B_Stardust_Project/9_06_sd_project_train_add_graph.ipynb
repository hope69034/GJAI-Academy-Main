{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPIO5mmUBqsvljYG59rgKkq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gvEcgyCxnRpO","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1662302881179,"user_tz":-540,"elapsed":392644,"user":{"displayName":"ᄋᄋ","userId":"14927427201019733620"}},"outputId":"cff73ac9-55ae-42d8-d5d7-379343d02959"},"outputs":[{"output_type":"stream","name":"stdout","text":["380\n","Loaded pretrained weights for efficientnet-b4\n","batch_size : 8,  train/val : 264 / 107\n","['model1']\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch /{}\n","----------\n","train Loss: 0.9723 Acc: 84.4697\n","Training epochs 0 in 0m 35s\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 1/10 [00:39<05:56, 39.64s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 1.4917 Acc: 13.0841\n","==> best model saved - 0 / 13.1\n","Training epochs 0 in 0m 40s\n","\n","Epoch /{}\n","----------\n","train Loss: 0.1982 Acc: 100.0000\n","Training epochs 1 in 0m 35s\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 2/10 [01:18<05:13, 39.20s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 2.2694 Acc: 14.0187\n","==> best model saved - 1 / 14.0\n","Training epochs 1 in 0m 39s\n","\n","Epoch /{}\n","----------\n","train Loss: 0.0395 Acc: 100.0000\n","Training epochs 2 in 0m 35s\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 3/10 [01:57<04:34, 39.24s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 3.2597 Acc: 14.0187\n","Training epochs 2 in 0m 39s\n","\n","Epoch /{}\n","----------\n","train Loss: 0.0192 Acc: 100.0000\n","Training epochs 3 in 0m 34s\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 4/10 [02:36<03:54, 39.04s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 4.0464 Acc: 14.0187\n","Training epochs 3 in 0m 39s\n","\n","Epoch /{}\n","----------\n","train Loss: 0.0114 Acc: 100.0000\n","Training epochs 4 in 0m 35s\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 5/10 [03:15<03:15, 39.05s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 4.5742 Acc: 14.0187\n","Training epochs 4 in 0m 39s\n","\n","Epoch /{}\n","----------\n","train Loss: 0.0083 Acc: 100.0000\n","Training epochs 5 in 0m 35s\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 6/10 [03:54<02:35, 38.99s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 4.8619 Acc: 14.0187\n","Training epochs 5 in 0m 39s\n","\n","Epoch /{}\n","----------\n","train Loss: 0.0064 Acc: 100.0000\n","Training epochs 6 in 0m 35s\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 7/10 [04:33<01:56, 39.00s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 5.1500 Acc: 14.0187\n","Training epochs 6 in 0m 39s\n","\n","Epoch /{}\n","----------\n","train Loss: 0.0055 Acc: 100.0000\n","Training epochs 7 in 0m 35s\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 8/10 [05:12<01:17, 38.99s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 5.2248 Acc: 14.0187\n","Training epochs 7 in 0m 39s\n","\n","Epoch /{}\n","----------\n","train Loss: 0.0055 Acc: 100.0000\n","Training epochs 8 in 0m 35s\n","\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 9/10 [05:51<00:39, 39.02s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 5.2920 Acc: 14.0187\n","Training epochs 8 in 0m 39s\n","\n","Epoch /{}\n","----------\n","train Loss: 0.0052 Acc: 100.0000\n","Training epochs 9 in 0m 35s\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [06:30<00:00, 39.05s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 5.3772 Acc: 14.0187\n","Training epochs 9 in 0m 39s\n","\n","Training complete in 6m 31s\n","Best valid Acc: 1 - 14.0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["model saved\n","end time : 0:06:31\n","best model : 1 - 14 / 2.3\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"execute_result","data":{"text/plain":["(EfficientNet(\n","   (_conv_stem): Conv2dStaticSamePadding(\n","     3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n","     (static_padding): ZeroPad2d((0, 1, 0, 1))\n","   )\n","   (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","   (_blocks): ModuleList(\n","     (0): MBConvBlock(\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         48, 12, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         12, 48, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (1): MBConvBlock(\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         24, 6, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         6, 24, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (2): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n","         (static_padding): ZeroPad2d((0, 1, 0, 1))\n","       )\n","       (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         144, 6, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         6, 144, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (3): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         192, 8, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         8, 192, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (4): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         192, 8, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         8, 192, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (5): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         192, 8, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         8, 192, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (6): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         192, 8, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         8, 192, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (7): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         336, 14, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         14, 336, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (8): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         336, 14, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         14, 336, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (9): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         336, 14, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         14, 336, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (10): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n","         (static_padding): ZeroPad2d((0, 1, 0, 1))\n","       )\n","       (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         336, 14, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         14, 336, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (11): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         672, 28, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         28, 672, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (12): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         672, 28, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         28, 672, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (13): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         672, 28, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         28, 672, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (14): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         672, 28, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         28, 672, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (15): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         672, 28, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         28, 672, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (16): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         672, 28, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         28, 672, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (17): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         960, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         40, 960, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (18): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         960, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         40, 960, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (19): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         960, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         40, 960, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (20): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         960, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         40, 960, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (21): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         960, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         40, 960, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (22): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n","         (static_padding): ZeroPad2d((1, 2, 1, 2))\n","       )\n","       (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         960, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         40, 960, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (23): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1632, 68, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         68, 1632, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (24): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1632, 68, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         68, 1632, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (25): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1632, 68, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         68, 1632, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (26): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1632, 68, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         68, 1632, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (27): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1632, 68, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         68, 1632, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (28): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1632, 68, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         68, 1632, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (29): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1632, 68, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         68, 1632, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (30): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1632, 68, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         68, 1632, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (31): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         2688, 112, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         112, 2688, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","   )\n","   (_conv_head): Conv2dStaticSamePadding(\n","     448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n","     (static_padding): Identity()\n","   )\n","   (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","   (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n","   (_dropout): Dropout(p=0.4, inplace=False)\n","   (_fc): Linear(in_features=1792, out_features=4, bias=True)\n","   (_swish): MemoryEfficientSwish()\n"," ),\n"," 1,\n"," 14.018691588785046,\n"," [0.9722600958564065,\n","  0.19816675917668777,\n","  0.039506531010071434,\n","  0.01918537700266549,\n","  0.011423396228840857,\n","  0.00831557811717644,\n","  0.006448375512704704,\n","  0.00550383340680238,\n","  0.005458944928691242,\n","  0.005222644551064481],\n"," [84.46969696969697,\n","  100.0,\n","  100.0,\n","  100.0,\n","  100.0,\n","  100.0,\n","  100.0,\n","  100.0,\n","  100.0,\n","  100.0],\n"," [1.4916759573410605,\n","  2.2693933983829533,\n","  3.2597230539143642,\n","  4.046393900134853,\n","  4.574232830204696,\n","  4.861905194401184,\n","  5.1500439893140975,\n","  5.224783557040669,\n","  5.29204826265852,\n","  5.377206499679623],\n"," [13.084112149532709,\n","  14.018691588785046,\n","  14.018691588785046,\n","  14.018691588785046,\n","  14.018691588785046,\n","  14.018691588785046,\n","  14.018691588785046,\n","  14.018691588785046,\n","  14.018691588785046,\n","  14.018691588785046])"]},"metadata":{},"execution_count":23}],"source":["#이피션트넷참고자료 https://keep-steady.tistory.com/35\n","#구글드라이브를 마운트 \n","from google.colab import drive\n","drive.mount('/content/drive')\n","#코랩용 설치\n","!pip install efficientnet_pytorch\n","#import, from\n","import time  # time() 함수 : 현재 Unix timestamp을 소수로 리턴,  정수부는 초단위이고 소수부는 마이크로 초단위\n","import datetime  # datetime.timedelta  : 기간을 표현하기 위해서 사용\n","import os\n","import copy  # 복사\n","import cv2\n","import random  # 랜덤\n","import numpy as np\n","import json  # JSON(JavaScript Object Notation), attribute–value pairs / array data types / any other serializable value 로 이루어진 데이터를 전달하기 텍스트를 사용하는 포맷\n","import torch  # facebook에서 제공하는 딥러닝 도구, numpy와 효율적인 연동을 지원\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torch.optim import lr_scheduler\n","from torchvision import transforms, datasets\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","import matplotlib.pyplot as plt  # 시각화\n","from PIL import Image  # PIL 이미지 제어\n","from efficientnet_pytorch import EfficientNet  # EfficientNet : 이미지 분류 최고의 모델\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # CUDA (Computed Unified Device Architecture)는 NVIDIA에서 개발한 GPU 개발 툴이다.\n","#model = model.to(device) # inputs = inputs.to(device) # labels = labels.to(device) # outputs = model(inputs) # 아웃풋 = 모델에디바이스(인풋에디바이스)\n","#torch.cuda.device(device) : 선택된 장치를 변경하는 context 관리자\n","#torch.cuda.device 의 파라미터 : device ( torch.device 또는 int ) – 선택할 장치 인덱스, 인수가 음의 정수 또는 None이면 작동X(no-op)\n","hyper_param_batch = 8  # 배치 사이즈 # 기본 4 이상( > 아웃풋4)\n","random_seed = 100  # 랜덤 시드\n","#random_seed = 100 활용, 랜덤값 고정\n","random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","#변수 선언\n","num_classes = 4  # 0 1 2 3  4가지로 분류  num_classes=num_classes   모델선언할 때  이피션트넷비7에 4가지클래스 0123 의모델 선언\n","model_name = 'efficientnet-b4'  # 진짜 모델 이름\n","train_name = 'model1'  # 트레인, 벨리, 테스트 셋 상위폴더 이름\n","#기존코드 : PATH = './scalp_weights/'     # 여기에 모델.pt가 save\n","PATH = '/content/drive/MyDrive/project/scalp_weights/'  # 코랩용\n","#기존코드\n","#data_train_path = './train_data/' + train_name + '/train'  # 현재폴더/train_data/model1/train\n","#data_validation_path = './train_data/' + train_name + '/validation'  # 현재폴더/train_data/model1/validation\n","#data_test_path = './train_data/' + train_name + '/test'  # 현재폴더/train_data/model1/test \n","#코랩용\n","data_train_path ='/content/drive/MyDrive/project/train_data/'+train_name+'/train' \n","data_validation_path = '/content/drive/MyDrive/project/train_data/'+train_name+'/validation' \n","data_test_path ='/content/drive/MyDrive/project/train_data/'+train_name+'/test' \n","image_size = EfficientNet.get_image_size(model_name)  # model_name = 'efficientnet-b7'\n","print(image_size)  # 600 출력\n","#모델선언\n","model = EfficientNet.from_pretrained(model_name, num_classes=num_classes)  # 이피션트넷 모델 선언 # 출력 pretrained weight 로드\n","num_classes = 4 # 이피션트넷 모델선언 (파라미터), 0 1 2 3  4가지\n","#model_name = 'efficientnet-b7' # 진짜 모델 이름\n","model = model.to(device)  # device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","#transforms.Compose : Rescale 과 RandomCrop 을 한번에 수행\n","#Rescale: 이미지의 크기를 조절\n","#RandomCrop: 이미지를 무작위로 자른다\n","#정규화\n","def func(x):  #아래 transforms_train = 코드에서 transforms.Lambda(lambda x: x.rotate(90)) 에서 나는 에러를 잡기 위해 def로 빼주고 람다 속 람다를 제거함\n","    return x.rotate(90)\n","transforms_train = transforms.Compose([ \n","    transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BOX), # interpolation=4 워닝을 제거하기 위해 변형\n","    transforms.RandomHorizontalFlip(p=0.5), #  interpolation 보간법 (두점을궤적으로연결하는방법, 알려진 지점 사이의 중간값을 추정하는 방법)\n","            #리사이즈할 때 이미지품질에 관여한다\n","    #InterpolationMode.NEAREST: 0,    최저품질\n","    #InterpolationMode.LANCZOS: 1,\n","    #InterpolationMode.BILINEAR: 2,\n","    #InterpolationMode.BICUBIC: 3,\n","    #InterpolationMode.BOX: 4,\n","    #InterpolationMode.HAMMING: 5     최고품질\n","        #예를 들어, 어떤 사람이 20살일때 키와 40살에서의 키를 보고 30살에서의 키를 추측하는 것은 interpolation이고 \n","        #과거 1살때부터 현재 나이까지의 키를 보고 앞으로 10년 후의 키를 예측하는 것은 extrapolation이다. \n","        #또한 최근 한달간의 주가 동향을 보고 내일의 주가를 예측하는 것도 extrapolation이며 extrapolation은 \n","        #interpolation에 비해 훨씬 안정성이 떨어지는 (위험한) 예측 방법이다.\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.Lambda(func),\n","    transforms.RandomRotation(10),\n","    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n","    transforms.ToTensor(), #텐서화\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #노말라이즈 정규화\n","])\n","#ImageNet은 입력이 224x224 형식이므로 이에 맞춰 Resize 해준다. 그리고 torch의 입력형태인 Tensor로 바꿔 준 후 Normalize 해준다.\n","transforms_val = transforms.Compose([\n","    transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BOX),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","#data_train_path 경로의 이미지를 transforms.Compose 로 규정한 규칙에 의해 정규화,텐서화 하며 (트랜스폼하며) 데이터를 불러옴\n","train_data_set = datasets.ImageFolder(data_train_path, transform=transforms_train)\n","val_data_set = datasets.ImageFolder(data_validation_path, transform=transforms_val)\n","#변수 선언\n","dataloaders, batch_num = {}, {}\n","#dataloaders 빈딕셔너리에 train/val 키랑 DataLoder 밸류 넣기\n","#DataLoader로 학습용 데이터 준비 : 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한다 (데이터와타겟/피처와정답)\n","dataloaders['train'] = DataLoader(train_data_set,\n","                                  batch_size=hyper_param_batch,\n","                                  shuffle=True,\n","                                  num_workers=2)  # aihub코드  num_workers = 4\n","dataloaders['val'] = DataLoader(val_data_set,\n","                                batch_size=hyper_param_batch,\n","                                shuffle=False,\n","                                num_workers=2)  # aihub코드  num_workers = 4\n","#즉 dataloaders 딕셔너리에는 train / val 이 key 각 밸류는 정규화한 이미지 데이터에 + 라벨이 붙음\n","#DataLoader를 통해 네트워크에 올리기\n","#from torch.utils.data import Dataset,DataLoader \n","#testloader = DataLoader(testset, batch_size=2, shuffle=False, num_workers=0)\n","    #데이터 로더는 데이터의 대량 가져오기 또는 내보내기를 위한 클라이언트 응용 프로그램 \n","    #for data, target in testloader: 에서 data는 데이터의 특징  target은 데이터의 정답값\n","#배치_넘은 빈 딕셔너리\n","#train/val 을 key로 각 밸류 선언\n","batch_num['train'], batch_num['val'] = len(train_data_set), len(val_data_set)\n","print('batch_size : %d,  train/val : %d / %d' % (hyper_param_batch, batch_num['train'], batch_num['val']))\n","#출력 :      batch_size : 6,   train/val :             2066       /         499\n","#      hyper_param_batch = 6    train/val :  len(train_data_set)   /    len(val_data_set)\n","class_names = train_data_set.classes  # train_data_set 정규화한 트레인셋\n","print(class_names)  # 출력 : [ '[원천]미세각질_0.양호', '[원천]미세각질_1.경증', '[원천]미세각질_2.중등도', '[원천]미세각질_3.중증'  ]\n","#def 선언 후 마지막에 train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs) 로 실행\n","from tqdm import tqdm # 진행률 표시를 위한\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    if __name__ == '__main__':  # 프롬프트에서 돌리기 위해 추가. 네임메인에 관해 런타임에러를 디버그 \n","        ##변수 선언\n","        #시간변수 선언\n","        start_time = time.time()  # end_sec 종료시간 = time.time() - start_time, # 종료시간 :\n","        since = time.time()  # time_elapsed 경과시간 = time.time() - since, # 경과시간 : 모든 에폭을 돌리는데 걸린 시간\n","        best_acc = 0.0  # 베스트 정확도 갱신시킬 변수\n","        best_model_wts = copy.deepcopy(model.state_dict())  # 베스트가중치도 갱신: 베스트 정확도 갱신할 때 같이 갱신\n","        #state_dict 는 간단히 말해 각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict) 객체입니다.\n","        #state_dict : 모델의 매개변수를 딕셔너리로 저장\n","        #copy.deepcopy 깊은복사: 완전한복사 (얕은복사:일종의 링크 형태)\n","        #손실, 정확도 빈리스트 선언\n","        train_loss, train_acc, val_loss, val_acc = [], [], [], []\n","        #for문\n","        for epoch in tqdm(range(num_epochs)):  # epoch만큼 실행\n","            print('Epoch /{{}}'.format(epoch, num_epochs - 1))  # 1000에폭을 넣으면 Epoch 0/999 이렇게 출력      왜 -1을 넣었을가 ?\n","            print('-' * 10)  # ---------- 구분 선\n","            epoch_start = time.time()  # 매 에폭을 돌리는 시간\n","            for phase in ['train', 'val']: # 에폭 1번 돌릴 때 학습모드페이즈~ 평가모드페이즈~ 한번씩 구동\n","                if phase == 'train':\n","                    model.train()  # model.train()  ≫ 모델을 학습 모드로 변환\n","                else:\n","                    model.eval()  # model.eval()  ≫ 모델을 평가 모드로 변환\n","                #train이 들어가면 학습모드로 아래 코드 실행, val이 들어가면 평가모드로 val로 평가\n","                #변수\n","                running_loss = 0.0\n","                running_corrects = 0\n","                num_cnt = 0\n","                #아래코드이해를위한\n","                #dataloaders 빈딕셔너리에 train/val 키랑 DataLoder 밸류 넣기\n","                #DataLoader로 학습용 데이터 준비 : 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한다\n","                #dataloaders['train'] = DataLoader(train_data_set,\n","                #                                   batch_size=hyper_param_batch,\n","                #                                   shuffle=True,\n","                #                                   num_workers=4)\n","                #dataloaders['val'] = DataLoader(val_data_set,\n","                #                                 batch_size=hyper_param_batch,\n","                #                                 shuffle=False,\n","                #                                 num_workers=4)\n","                for inputs, labels in dataloaders[phase]:  # phase 에 train or val 이 들어가서 인풋과 라벨로 나뉜다\n","                  #위에서 데이터로더 딕셔너리에 트레인과 벨리셋 두개로 나눴다 그리고 데이터로더에서 이터러블하게 뽑으면서 데이터의 특징과정답값을 뽑는다\n","                    inputs = inputs.to(device) # inputs 은 데이터의 피처\n","                    labels = labels.to(device)  # labels 는 데이터의 정답 / 폴더세팅에 따라 (폴더이름오름차순) 정답값이 자동으로 설정\n","                    optimizer.zero_grad()  # optimizer.zero_grad() : Pytorch에서는 gradients값들을 추후에 backward를 해줄때 계속 더해주기 때문\"에\n","                    #우리는 항상 backpropagation을 하기전에 gradients를 zero로 만들어주고 시작을 해야합니다.\n","                    #한번 학습이 완료가 되면 gradients를 0으로 초기화\n","                    with torch.set_grad_enabled(phase == 'train'): # 트레인페이즈라 그래디언트 계산은 활성화한다\n","                        #torch.set_grad_enabled\n","                        #그래디언트 계산을 켜키거나 끄는 설정을 하는 컨텍스트 관리자\n","                        #phase == 'train' 이 true 면 gradients를 활성화 한다.\n","                        outputs = model(inputs)  # 모델에 데이터의 피처를 넣어서 아웃풋 생성\n","                        _, preds = torch.max(outputs, 1)  # _, preds ?\n","                        #torch.max(input-tensor) : 인풋에서 최댓값을 리턴하는데 tensor라 각 묶음마다 최댓값을 받고 ,1 은 축소할 차원이1이라는 뜻\n","                        loss = criterion(outputs, labels)  # 로스 계산\n","                        #매 epoch, 매 iteration 마다 back propagation을 통해 모델의 파라미터를 업데이트 시켜주는 과정이 필요한데,\n","                        #아래 다섯 줄의 코드는 공식처럼 외우는 것을 추천드립니다.\n","                        #optimizer.zero_grad()   \t# init grad\n","                        #pred = model(x)  # forward\n","                        #loss = criterion(pred, x_labels) # 로스 계산\n","                        #loss.backward()  # backpropagation\n","                        #optimizer.step()  \t# weight update\n","                        if phase == 'train':\n","                            loss.backward()  # backpropagation\n","                            optimizer.step()  # weight update\n","                    running_loss += loss.item() * inputs.size(0)  # 학습과정 출력   #   running_loss = 0.0    # loss 는 로스계산  ?\n","                    running_corrects += torch.sum(preds == labels.data)  # running_corrects = 0                    ?\n","                    num_cnt += len(labels)  # num_cnt = 0                             ?\n","                #for inputs, labels in dataloaders[phase]: # phase 에 train or val 이 들어가서 인풋과 라벨로 나뉜다\n","                #                 inputs = inputs.to(device)\n","                #                 labels = labels.to(device)\n","                if phase == 'train':\n","                    scheduler.step()  # 학습 규제\n","                #학습률이 크면 가중치 업데이트가 많아 가중치가 overflow 될 수도 있습니다\n","                #훈련 초기에 학습률은 충분히 좋은 가중치에 도달하기 위해 크게 설정됩니다. 시간이 지남에 따라\n","                #이러한 가중치는 작은 학습률을 활용하여 더 높은 정확도에 도달하도록 미세 조정됩니다.\n","                #결국, 가중치를 규제(regularization)하는 방식과 비슷하게, 학습률을 규제하는(Learning Rate Decay)것이 Learning Rate Scheduler라고 할 수 있습니다.\n","                #optimizer와 scheduler를 먼저 정의한 후, 학습할 때 batch마다 optimizer.step() 하고 epoch마다 scheduler.step()을 해주면 됩니다.\n","                #def 밖에서  op sc 선언 def안에서 op.step  sc.stop 완료\n","                epoch_loss = float(running_loss / num_cnt)  # ? 에폭손실\n","                epoch_acc = float((running_corrects.double() / num_cnt).cpu() * 100)  # ? 에폭 정확도\n","                #     손실, 정확도 빈리스트 선언\n","                #     train_loss, train_acc, val_loss, val_acc = [], [], [], []\n","                if phase == 'train':\n","                    train_loss.append(epoch_loss)\n","                    train_acc.append(epoch_acc)\n","                else:\n","                    val_loss.append(epoch_loss)\n","                    val_acc.append(epoch_acc)\n","                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))  # 출력 train/val, 손실, 정확도\n","            #deep copy the model\n","                if phase == 'val' and epoch_acc > best_acc:\n","                    best_idx = epoch   \n","                    best_acc = epoch_acc\n","                    best_model_wts = copy.deepcopy(model.state_dict())\n","                    print('==> best model saved - %d / %.1f' % (best_idx, best_acc))  # 몇번째 에폭의 베스트 정확도가 세이브되었나 출력\n","                #     best_acc = 0.0 # 베스트 정확도 갱신시킬 변수\n","                #     best_model_wts = copy.deepcopy(model.state_dict()) # 베스트가중치도 갱신: 베스트 정확도 갱신할 때 같이 갱신\n","                #state_dict 는 간단히 말해 각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict) 객체입니다.\n","                #state_dict : 모델의 매개변수를 딕셔너리로 저장\n","                #copy.deepcopy 깊은복사: 완전한복사 (얕은복사:일종의 링크 형태)\n","                epoch_end = time.time() - epoch_start  # train/val 전부 에폭 한번 돌리는 시간을 구해서 아래 출력\n","                print('Training epochs {} in {:.0f}m {:.0f}s'.format(epoch, epoch_end // 60,\n","                                                                    epoch_end % 60))  # 트레이닝에폭 epoch 몇분 몇초\n","                print()\n","                #for문 끝\n","    time_elapsed = time.time() - since  # 경과시간 : 모든 에폭을 돌리는데 걸린 시간, for 문이 끝났으니까\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))  # 경과시간을 몇분 몇초로 출력\n","    print('Best valid Acc: %d - %.1f' % (best_idx, best_acc))  # best_idx : 몇번째 에폭이 베스트인지, 베스트정확도 출력\n","#load best model weights  \n","    model.load_state_dict(best_model_wts)  # state_dict: 모델의 매개변수를 딕셔너리에 담은 > 것을 load 한다\n","    #best_model_wts = copy.deepcopy(model.state_dict())\n","    #PATH = './scalp_weights/' # 경로 설정 현재폴더 하위에 scalp_weights 폴더\n","    torch.save(model, PATH + 'aram_' + train_name + '.pt')  # 모델을 PATH경로에 aram_트레인네임(model1).pt 라는 이름으로 저장한다\n","    torch.save(model.state_dict(), PATH + 'president_aram_' + train_name + '.pt')  # 모델의 매개변수를               -  저장\n","    print('model saved')\n","    end_sec = time.time() - start_time  # 종료시간    # 초단위에서\n","    end_times = str(datetime.timedelta(seconds=end_sec)).split('.')  # 시분초로 치환\n","    #import datetime\n","    #end = 8888\n","    #datetime.timedelta(seconds=end)                                #출력  datetime.timedelta(seconds=8888)\n","    #str(datetime.timedelta(seconds=end))  # type str              #출력  '2:28:08'\n","    #str(datetime.timedelta(seconds=end)).split('.') # type list   #출력   ['2:28:08']  ?\n","    #str(datetime.timedelta(seconds=end)).split('.')[0] # type str  #출력  '2:28:08'\n","    end_time = end_times[0]  # 종료시간 시분초\n","    print(\"end time :\", end_time)  # 출력\n","    ################################\n","    ##에폭별 아큐러시 그래프 그리기\n","    print('best model : %d - %1.f / %.1f'%(best_idx, val_acc[best_idx], val_loss[best_idx]))\n","    fig, ax1 = plt.subplots()\n","    ax1.plot(train_acc, 'b-') #선그래프Y축\n","    ax1.plot(val_acc, 'r-') #선그래프Y축\n","    plt.plot(best_idx, val_acc[best_idx], 'ro') #벨리셋 아큐러시 최대치 나오는 지점을 점 찍어주기\n","    ax1.set_xlabel('epoch') \n","    #Make the y-axis label, ticks and tick labels match the line color.\n","    ax1.set_ylabel('acc', color='k')\n","    ax1.tick_params('y', colors='k')\n","    #ax2 = ax1.twinx()\n","    #ax2.plot(train_loss, 'g-')\n","    #ax2.plot(val_loss, 'k-')\n","    #plt.plot(best_idx, val_loss[best_idx], 'ro')\n","    #ax2.set_ylabel('loss', color='k')\n","    #ax2.tick_params('y', colors='k')\n","    fig.tight_layout()\n","    plt.show() #그래프 출력\n","    ################################\n","    return model, best_idx, best_acc, train_loss, train_acc, val_loss, val_acc\n","    #def 문 끝\n","#def실행할 train_model 파라미터 선언\n","#model = EfficientNet.from_pretrained(model_name, num_classes=num_classes).to(device)  # 첫번째 파라미터 (위에서 선언)\n","criterion = nn.CrossEntropyLoss()  # 두번째 파라미터\n","optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)  # 세번째 파라미터\n","exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)  # 네번째 파라미터  # 스케줄러 선언\n","num_epochs = 10 # 다섯번째 파라미터 # 에폭2 에 31분 걸림\n","#def 문 실행\n","train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)"]}]}