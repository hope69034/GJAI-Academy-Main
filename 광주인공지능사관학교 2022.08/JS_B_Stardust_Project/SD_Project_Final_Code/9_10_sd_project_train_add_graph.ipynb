{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b62817c0ade5421890c23ff25b94c9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86696cd3a1cd4fd1897c5233371ed369",
              "IPY_MODEL_e3984610611f43c59f27c86ece1636c7",
              "IPY_MODEL_5fd647032b4a49caba071bfe05bf7829"
            ],
            "layout": "IPY_MODEL_b44494a54c484a48b98a5359feee056e"
          }
        },
        "86696cd3a1cd4fd1897c5233371ed369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45eb15ecaa37457c83d503bec4cdd2e2",
            "placeholder": "​",
            "style": "IPY_MODEL_833faa6f5a664f6f88c2f49efc9291d2",
            "value": "100%"
          }
        },
        "e3984610611f43c59f27c86ece1636c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c8994717ea84b9087708e255aef2c8e",
            "max": 77999237,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8758b886308248058cb60dc7fd08a945",
            "value": 77999237
          }
        },
        "5fd647032b4a49caba071bfe05bf7829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81aef23efbf1412dafcaf963639dbd55",
            "placeholder": "​",
            "style": "IPY_MODEL_b32bd6c75d9a424296f994c454032ba1",
            "value": " 74.4M/74.4M [00:15&lt;00:00, 2.50MB/s]"
          }
        },
        "b44494a54c484a48b98a5359feee056e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45eb15ecaa37457c83d503bec4cdd2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "833faa6f5a664f6f88c2f49efc9291d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c8994717ea84b9087708e255aef2c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8758b886308248058cb60dc7fd08a945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81aef23efbf1412dafcaf963639dbd55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32bd6c75d9a424296f994c454032ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvEcgyCxnRpO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802,
          "referenced_widgets": [
            "b62817c0ade5421890c23ff25b94c9a7",
            "86696cd3a1cd4fd1897c5233371ed369",
            "e3984610611f43c59f27c86ece1636c7",
            "5fd647032b4a49caba071bfe05bf7829",
            "b44494a54c484a48b98a5359feee056e",
            "45eb15ecaa37457c83d503bec4cdd2e2",
            "833faa6f5a664f6f88c2f49efc9291d2",
            "8c8994717ea84b9087708e255aef2c8e",
            "8758b886308248058cb60dc7fd08a945",
            "81aef23efbf1412dafcaf963639dbd55",
            "b32bd6c75d9a424296f994c454032ba1"
          ]
        },
        "outputId": "671c4638-3681-4506-a9a2-838944d80007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (4.1.1)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=c473562b00c108b9bbcc9e4279d42d93cfb773256f2cd7022416eff22bca6803\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n",
            "380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/74.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b62817c0ade5421890c23ff25b94c9a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b4\n",
            "batch_size : 8,  train/val : 264 / 107\n",
            "['model1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch /{}\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:30<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-62b0e073ec7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;31m# 다섯번째 파라미터 # 에폭2 에 31분 걸림\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;31m#def 문 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-62b0e073ec7a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;31m#                                 shuffle=False,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m#                                 num_workers=4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# phase 에 train or val 이 들어가서 인풋과 라벨로 나뉜다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                   \u001b[0;31m#위에서 데이터로더 딕셔너리에 트레인과 벨리셋 두개로 나눴다 그리고 데이터로더에서 이터러블하게 뽑으면서 데이터의 특징과정답값을 뽑는다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# inputs 은 데이터의 피처\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#이피션트넷참고자료 https://keep-steady.tistory.com/35\n",
        "#구글드라이브를 마운트 \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#코랩용 설치\n",
        "!pip install efficientnet_pytorch\n",
        "#import, from\n",
        "import time  # time() 함수 : 현재 Unix timestamp을 소수로 리턴,  정수부는 초단위이고 소수부는 마이크로 초단위\n",
        "import datetime  # datetime.timedelta  : 기간을 표현하기 위해서 사용\n",
        "import os\n",
        "import copy  # 복사\n",
        "import cv2\n",
        "import random  # 랜덤\n",
        "import numpy as np\n",
        "import json  # JSON(JavaScript Object Notation), attribute–value pairs / array data types / any other serializable value 로 이루어진 데이터를 전달하기 텍스트를 사용하는 포맷\n",
        "import torch  # facebook에서 제공하는 딥러닝 도구, numpy와 효율적인 연동을 지원\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt  # 시각화\n",
        "from PIL import Image  # PIL 이미지 제어\n",
        "from efficientnet_pytorch import EfficientNet  # EfficientNet : 이미지 분류 최고의 모델\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # CUDA (Computed Unified Device Architecture)는 NVIDIA에서 개발한 GPU 개발 툴이다.\n",
        "#cpu\n",
        "#코어 개수 1~16 : 싱글코어 또는 멀티프로세싱을 활용한 보유 코어 만큼의 멀티코어\n",
        "#코어별 속도는 시피유가 빠르기 때문에 직렬연산{재귀연산(recursive연산)}에 좋다\n",
        "#gpu\n",
        "#코어 개수 몇천개 이상\n",
        "#멀티코어 > 병렬연산에 좋다\n",
        "#model = model.to(device) # inputs = inputs.to(device) # labels = labels.to(device) # outputs = model(inputs) # 아웃풋 = 모델에디바이스(인풋에디바이스)\n",
        "#torch.cuda.device(device) : 선택된 장치를 변경하는 context 관리자\n",
        "#torch.cuda.device 의 파라미터 : device ( torch.device 또는 int ) – 선택할 장치 인덱스, 인수가 음의 정수 또는 None이면 작동X(no-op)\n",
        "hyper_param_batch = 8  # 배치 사이즈 # 기본 4 이상( > 아웃풋4)\n",
        "random_seed = 100  # 랜덤 시드\n",
        "#random_seed = 100 활용, 랜덤값 고정\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "#변수 선언\n",
        "num_classes = 4  # 0 1 2 3  4가지로 분류  num_classes=num_classes   모델선언할 때  이피션트넷비7에 4가지클래스 0123 의모델 선언\n",
        "model_name = 'efficientnet-b4'  # 진짜 모델 이름\n",
        "# b0 ~ b7 : b0 이 가장 가볍고 파라미터가 적다 위 숫자 수정하여 변경 가능\n",
        "train_name = 'model1'  # 트레인, 벨리, 테스트 셋 상위폴더 이름\n",
        "#기존코드 : PATH = './scalp_weights/'     # 여기에 모델.pt가 save\n",
        "PATH = '/content/drive/MyDrive/project/scalp_weights/'  # 코랩용\n",
        "#기존코드\n",
        "#data_train_path = './train_data/' + train_name + '/train'  # 현재폴더/train_data/model1/train\n",
        "#data_validation_path = './train_data/' + train_name + '/validation'  # 현재폴더/train_data/model1/validation\n",
        "#data_test_path = './train_data/' + train_name + '/test'  # 현재폴더/train_data/model1/test \n",
        "#코랩용\n",
        "data_train_path ='/content/drive/MyDrive/project/train_data/'+train_name+'/train' \n",
        "data_validation_path = '/content/drive/MyDrive/project/train_data/'+train_name+'/validation' \n",
        "data_test_path ='/content/drive/MyDrive/project/train_data/'+train_name+'/test' \n",
        "image_size = EfficientNet.get_image_size(model_name)  # model_name = 'efficientnet-b7'\n",
        "print(image_size)  # 600 출력\n",
        "#모델선언\n",
        "model = EfficientNet.from_pretrained(model_name, num_classes=num_classes)  # 이피션트넷 모델 선언 # 출력 pretrained weight 로드\n",
        "num_classes = 4 # 이피션트넷 모델선언 (파라미터), 0 1 2 3  4가지\n",
        "#model_name = 'efficientnet-b7' # 진짜 모델 이름\n",
        "model = model.to(device)  # device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "#transforms.Compose : Rescale 과 RandomCrop 을 한번에 수행\n",
        "#Rescale: 이미지의 크기를 조절\n",
        "#RandomCrop: 이미지를 무작위로 자른다\n",
        "#정규화\n",
        "def func(x):  #아래 transforms_train = 코드에서 transforms.Lambda(lambda x: x.rotate(90)) 에서 나는 에러를 잡기 위해 def로 빼주고 람다 속 람다를 제거함\n",
        "    return x.rotate(90)\n",
        "transforms_train = transforms.Compose([ \n",
        "    transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BOX), # interpolation=4 워닝을 제거하기 위해 변형\n",
        "    transforms.RandomHorizontalFlip(p=0.5), #  interpolation 보간법 (두점을궤적으로연결하는방법, 알려진 지점 사이의 중간값을 추정하는 방법)\n",
        "            #리사이즈할 때 이미지품질에 관여한다\n",
        "    #InterpolationMode.NEAREST: 0,    최저품질\n",
        "    #InterpolationMode.LANCZOS: 1,\n",
        "    #InterpolationMode.BILINEAR: 2,\n",
        "    #InterpolationMode.BICUBIC: 3,\n",
        "    #InterpolationMode.BOX: 4,\n",
        "    #InterpolationMode.HAMMING: 5     최고품질\n",
        "        #예를 들어, 어떤 사람이 20살일때 키와 40살에서의 키를 보고 30살에서의 키를 추측하는 것은 interpolation이고 \n",
        "        #과거 1살때부터 현재 나이까지의 키를 보고 앞으로 10년 후의 키를 예측하는 것은 extrapolation이다. \n",
        "        #또한 최근 한달간의 주가 동향을 보고 내일의 주가를 예측하는 것도 extrapolation이며 extrapolation은 \n",
        "        #interpolation에 비해 훨씬 안정성이 떨어지는 (위험한) 예측 방법이다.\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.Lambda(func),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
        "    transforms.ToTensor(), #텐서화\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #노말라이즈 정규화\n",
        "])\n",
        "#ImageNet은 입력이 224x224 형식이므로 이에 맞춰 Resize 해준다. 그리고 torch의 입력형태인 Tensor로 바꿔 준 후 Normalize 해준다.\n",
        "transforms_val = transforms.Compose([\n",
        "    transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BOX),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "#data_train_path 경로의 이미지를 transforms.Compose 로 규정한 규칙에 의해 정규화,텐서화 하며 (트랜스폼하며) 데이터를 불러옴\n",
        "train_data_set = datasets.ImageFolder(data_train_path, transform=transforms_train)\n",
        "val_data_set = datasets.ImageFolder(data_validation_path, transform=transforms_val)\n",
        "#변수 선언\n",
        "dataloaders, batch_num = {}, {}\n",
        "#dataloaders 빈딕셔너리에 train/val 키랑 DataLoder 밸류 넣기\n",
        "#DataLoader로 학습용 데이터 준비 : 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한다 (데이터와타겟/피처와정답)\n",
        "dataloaders['train'] = DataLoader(train_data_set,\n",
        "                                  batch_size=hyper_param_batch,\n",
        "                                  shuffle=True,\n",
        "                                  num_workers=2)  # aihub코드  num_workers = 4\n",
        "dataloaders['val'] = DataLoader(val_data_set,\n",
        "                                batch_size=hyper_param_batch,\n",
        "                                shuffle=False,\n",
        "                                num_workers=2)  # aihub코드  num_workers = 4\n",
        "#즉 dataloaders 딕셔너리에는 train / val 이 key 각 밸류는 정규화한 이미지 데이터에 + 라벨이 붙음\n",
        "#DataLoader를 통해 네트워크에 올리기\n",
        "#from torch.utils.data import Dataset,DataLoader \n",
        "#testloader = DataLoader(testset, batch_size=2, shuffle=False, num_workers=0)\n",
        "    #데이터 로더는 데이터의 대량 가져오기 또는 내보내기를 위한 클라이언트 응용 프로그램 \n",
        "    #for data, target in testloader: 에서 data는 데이터의 특징  target은 데이터의 정답값\n",
        "#배치_넘은 빈 딕셔너리\n",
        "#train/val 을 key로 각 밸류 선언\n",
        "batch_num['train'], batch_num['val'] = len(train_data_set), len(val_data_set)\n",
        "print('batch_size : %d,  train/val : %d / %d' % (hyper_param_batch, batch_num['train'], batch_num['val']))\n",
        "#출력 :      batch_size : 6,   train/val :             2066       /         499\n",
        "#      hyper_param_batch = 6    train/val :  len(train_data_set)   /    len(val_data_set)\n",
        "class_names = train_data_set.classes  # train_data_set 정규화한 트레인셋\n",
        "print(class_names)  # 출력 : [ '[원천]미세각질_0.양호', '[원천]미세각질_1.경증', '[원천]미세각질_2.중등도', '[원천]미세각질_3.중증'  ]\n",
        "#def 선언 후 마지막에 train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs) 로 실행\n",
        "from tqdm import tqdm # 진행률 표시를 위한\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    if __name__ == '__main__':  # 프롬프트에서 돌리기 위해 추가. 네임메인에 관해 런타임에러를 디버그 \n",
        "        ##변수 선언\n",
        "        #시간변수 선언\n",
        "        start_time = time.time()  # end_sec 종료시간 = time.time() - start_time, # 종료시간 :\n",
        "        since = time.time()  # time_elapsed 경과시간 = time.time() - since, # 경과시간 : 모든 에폭을 돌리는데 걸린 시간\n",
        "        best_acc = 0.0  # 베스트 정확도 갱신시킬 변수\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())  # 베스트가중치도 갱신: 베스트 정확도 갱신할 때 같이 갱신\n",
        "        #state_dict 는 간단히 말해 각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict) 객체입니다.\n",
        "        #state_dict : 모델의 매개변수를 딕셔너리로 저장\n",
        "        #copy.deepcopy 깊은복사: 완전한복사 (얕은복사:일종의 링크 형태)\n",
        "        #손실, 정확도 빈리스트 선언\n",
        "        train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
        "        #for문\n",
        "        for epoch in tqdm(range(num_epochs)):  # epoch만큼 실행\n",
        "            print('Epoch /{{}}'.format(epoch, num_epochs - 1))  # 1000에폭을 넣으면 Epoch 0/999 이렇게 출력      왜 -1을 넣었을가 ?\n",
        "            print('-' * 10)  # ---------- 구분 선\n",
        "            epoch_start = time.time()  # 매 에폭을 돌리는 시간\n",
        "            for phase in ['train', 'val']: # 에폭 1번 돌릴 때 학습모드페이즈~ 평가모드페이즈~ 한번씩 구동\n",
        "                if phase == 'train':\n",
        "                    model.train()  # model.train()  ≫ 모델을 학습 모드로 변환\n",
        "                else:\n",
        "                    model.eval()  # model.eval()  ≫ 모델을 평가 모드로 변환\n",
        "                #train이 들어가면 학습모드로 아래 코드 실행, val이 들어가면 평가모드로 val로 평가\n",
        "                #변수\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "                num_cnt = 0\n",
        "                #아래코드이해를위한\n",
        "                #dataloaders 빈딕셔너리에 train/val 키랑 DataLoder 밸류 넣기\n",
        "                #DataLoader로 학습용 데이터 준비 : 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한다\n",
        "                #dataloaders['train'] = DataLoader(train_data_set,\n",
        "                #                                   batch_size=hyper_param_batch,\n",
        "                #                                   shuffle=True,\n",
        "                #                                   num_workers=4)\n",
        "                #dataloaders['val'] = DataLoader(val_data_set,\n",
        "                #                                 batch_size=hyper_param_batch,\n",
        "                #                                 shuffle=False,\n",
        "                #                                 num_workers=4)\n",
        "                for inputs, labels in dataloaders[phase]:  # phase 에 train or val 이 들어가서 인풋과 라벨로 나뉜다\n",
        "                  #위에서 데이터로더 딕셔너리에 트레인과 벨리셋 두개로 나눴다 그리고 데이터로더에서 이터러블하게 뽑으면서 데이터의 특징과정답값을 뽑는다\n",
        "                    inputs = inputs.to(device) # inputs 은 데이터의 피처\n",
        "                    labels = labels.to(device)  # labels 는 데이터의 정답 / 폴더세팅에 따라 (폴더이름오름차순) 정답값이 자동으로 설정\n",
        "                    optimizer.zero_grad()  # optimizer.zero_grad() : Pytorch에서는 gradients값들을 추후에 backward를 해줄때 계속 더해주기 때문\"에\n",
        "                    #우리는 항상 backpropagation을 하기전에 gradients를 zero로 만들어주고 시작을 해야합니다.\n",
        "                    #한번 학습이 완료가 되면 gradients를 0으로 초기화\n",
        "                    with torch.set_grad_enabled(phase == 'train'): # 트레인페이즈라 그래디언트 계산은 활성화한다\n",
        "                        #torch.set_grad_enabled\n",
        "                        #그래디언트 계산을 켜키거나 끄는 설정을 하는 컨텍스트 관리자\n",
        "                        #phase == 'train' 이 true 면 gradients를 활성화 한다.\n",
        "                        outputs = model(inputs)  # 모델에 데이터의 피처를 넣어서 아웃풋 생성\n",
        "                        _, preds = torch.max(outputs, 1)  # _, preds ?\n",
        "                        #torch.max(input-tensor) : 인풋에서 최댓값을 리턴하는데 tensor라 각 묶음마다 최댓값을 받고 ,1 은 축소할 차원이1이라는 뜻\n",
        "                        loss = criterion(outputs, labels)  # 로스 계산\n",
        "                        #매 epoch, 매 iteration 마다 back propagation을 통해 모델의 파라미터를 업데이트 시켜주는 과정이 필요한데,\n",
        "                        #아래 다섯 줄의 코드는 공식처럼 외우는 것을 추천드립니다.\n",
        "                        #optimizer.zero_grad()   \t# init grad\n",
        "                        #pred = model(x)  # forward\n",
        "                        #loss = criterion(pred, x_labels) # 로스 계산\n",
        "                        #loss.backward()  # backpropagation\n",
        "                        #optimizer.step()  \t# weight update\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()  # backpropagation\n",
        "                            optimizer.step()  # weight update\n",
        "                    running_loss += loss.item() * inputs.size(0)  # 학습과정 출력   #   running_loss = 0.0    # loss 는 로스계산  ?\n",
        "                    running_corrects += torch.sum(preds == labels.data)  # running_corrects = 0                    ?\n",
        "                    num_cnt += len(labels)  # num_cnt = 0                             ?\n",
        "                #for inputs, labels in dataloaders[phase]: # phase 에 train or val 이 들어가서 인풋과 라벨로 나뉜다\n",
        "                #                 inputs = inputs.to(device)\n",
        "                #                 labels = labels.to(device)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()  # 학습 규제\n",
        "                #학습률이 크면 가중치 업데이트가 많아 가중치가 overflow 될 수도 있습니다\n",
        "                #훈련 초기에 학습률은 충분히 좋은 가중치에 도달하기 위해 크게 설정됩니다. 시간이 지남에 따라\n",
        "                #이러한 가중치는 작은 학습률을 활용하여 더 높은 정확도에 도달하도록 미세 조정됩니다.\n",
        "                #결국, 가중치를 규제(regularization)하는 방식과 비슷하게, 학습률을 규제하는(Learning Rate Decay)것이 Learning Rate Scheduler라고 할 수 있습니다.\n",
        "                #optimizer와 scheduler를 먼저 정의한 후, 학습할 때 batch마다 optimizer.step() 하고 epoch마다 scheduler.step()을 해주면 됩니다.\n",
        "                #def 밖에서  op sc 선언 def안에서 op.step  sc.stop 완료\n",
        "                epoch_loss = float(running_loss / num_cnt)  # ? 에폭손실\n",
        "                epoch_acc = float((running_corrects.double() / num_cnt).cpu() * 100)  # ? 에폭 정확도\n",
        "                #     손실, 정확도 빈리스트 선언\n",
        "                #     train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
        "                if phase == 'train':\n",
        "                    train_loss.append(epoch_loss)\n",
        "                    train_acc.append(epoch_acc)\n",
        "                else:\n",
        "                    val_loss.append(epoch_loss)\n",
        "                    val_acc.append(epoch_acc)\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))  # 출력 train/val, 손실, 정확도\n",
        "            #deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_idx = epoch   \n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    print('==> best model saved - %d / %.1f' % (best_idx, best_acc))  # 몇번째 에폭의 베스트 정확도가 세이브되었나 출력\n",
        "                #     best_acc = 0.0 # 베스트 정확도 갱신시킬 변수\n",
        "                #     best_model_wts = copy.deepcopy(model.state_dict()) # 베스트가중치도 갱신: 베스트 정확도 갱신할 때 같이 갱신\n",
        "                #state_dict 는 간단히 말해 각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict) 객체입니다.\n",
        "                #state_dict : 모델의 매개변수를 딕셔너리로 저장\n",
        "                #copy.deepcopy 깊은복사: 완전한복사 (얕은복사:일종의 링크 형태)\n",
        "                epoch_end = time.time() - epoch_start  # train/val 전부 에폭 한번 돌리는 시간을 구해서 아래 출력\n",
        "                print('Training epochs {} in {:.0f}m {:.0f}s'.format(epoch, epoch_end // 60,\n",
        "                                                                    epoch_end % 60))  # 트레이닝에폭 epoch 몇분 몇초\n",
        "                print()\n",
        "                #for문 끝\n",
        "    time_elapsed = time.time() - since  # 경과시간 : 모든 에폭을 돌리는데 걸린 시간, for 문이 끝났으니까\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))  # 경과시간을 몇분 몇초로 출력\n",
        "    print('Best valid Acc: %d - %.1f' % (best_idx, best_acc))  # best_idx : 몇번째 에폭이 베스트인지, 베스트정확도 출력\n",
        "#load best model weights  \n",
        "    model.load_state_dict(best_model_wts)  # state_dict: 모델의 매개변수를 딕셔너리에 담은 > 것을 load 한다\n",
        "    #best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    #PATH = './scalp_weights/' # 경로 설정 현재폴더 하위에 scalp_weights 폴더\n",
        "    torch.save(model, PATH + 'aram_' + train_name + '.pt')  # 모델을 PATH경로에 aram_트레인네임(model1).pt 라는 이름으로 저장한다\n",
        "    torch.save(model.state_dict(), PATH + 'president_aram_' + train_name + '.pt')  # 모델의 매개변수를               -  저장\n",
        "    print('model saved')\n",
        "    end_sec = time.time() - start_time  # 종료시간    # 초단위에서\n",
        "    end_times = str(datetime.timedelta(seconds=end_sec)).split('.')  # 시분초로 치환\n",
        "    #import datetime\n",
        "    #end = 8888\n",
        "    #datetime.timedelta(seconds=end)                                #출력  datetime.timedelta(seconds=8888)\n",
        "    #str(datetime.timedelta(seconds=end))  # type str              #출력  '2:28:08'\n",
        "    #str(datetime.timedelta(seconds=end)).split('.') # type list   #출력   ['2:28:08']  ?\n",
        "    #str(datetime.timedelta(seconds=end)).split('.')[0] # type str  #출력  '2:28:08'\n",
        "    end_time = end_times[0]  # 종료시간 시분초\n",
        "    print(\"end time :\", end_time)  # 출력\n",
        "    ################################\n",
        "    ##에폭별 아큐러시 그래프 그리기\n",
        "    print('best model : %d - %1.f / %.1f'%(best_idx, val_acc[best_idx], val_loss[best_idx]))\n",
        "    fig, ax1 = plt.subplots()\n",
        "    ax1.plot(train_acc, 'b-') #선그래프Y축\n",
        "    ax1.plot(val_acc, 'r-') #선그래프Y축\n",
        "    plt.plot(best_idx, val_acc[best_idx], 'ro') #벨리셋 아큐러시 최대치 나오는 지점을 점 찍어주기\n",
        "    ax1.set_xlabel('epoch') \n",
        "    #Make the y-axis label, ticks and tick labels match the line color.\n",
        "    ax1.set_ylabel('acc', color='k')\n",
        "    ax1.tick_params('y', colors='k')\n",
        "    #ax2 = ax1.twinx()\n",
        "    #ax2.plot(train_loss, 'g-')\n",
        "    #ax2.plot(val_loss, 'k-')\n",
        "    #plt.plot(best_idx, val_loss[best_idx], 'ro')\n",
        "    #ax2.set_ylabel('loss', color='k')\n",
        "    #ax2.tick_params('y', colors='k')\n",
        "    fig.tight_layout()\n",
        "    plt.show() #그래프 출력\n",
        "    ################################\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, val_loss, val_acc\n",
        "    #def 문 끝\n",
        "#def실행할 train_model 파라미터 선언\n",
        "#model = EfficientNet.from_pretrained(model_name, num_classes=num_classes).to(device)  # 첫번째 파라미터 (위에서 선언)\n",
        "criterion = nn.CrossEntropyLoss()  # 두번째 파라미터\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)  # 세번째 파라미터\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)  # 네번째 파라미터  # 스케줄러 선언\n",
        "num_epochs = 10 # 다섯번째 파라미터 # 에폭2 에 31분 걸림\n",
        "#def 문 실행\n",
        "train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)"
      ]
    }
  ]
}