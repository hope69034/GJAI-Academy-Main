{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_24.sd.project.model6.accuracy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 배치1에폭2 미완성 모델로 돌려보는 코드\n",
        "\n",
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAeaJcNsgKKy",
        "outputId": "468eb1ae-c826-4c36-e864-51ba15b942db"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXmcV73XcL9T",
        "outputId": "44d18854-64b3-46e4-de52-18fff0ab0e7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (4.1.1)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=408d03937afe0ed7d734167eef4f595df9f8cc0b315f37d3c16ccffe69a52bd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch"
      ],
      "metadata": {
        "id": "87NbPNISgcIN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i0X9JzBGb0XE"
      },
      "outputs": [],
      "source": [
        "# 모델경로\n",
        "PATH6 = '/content/drive/MyDrive/Colab Notebooks/scalp_weights/'+'aram_model6.pt'  \n",
        "\n",
        "# Cuda\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model6 = torch.load(PATH6, map_location=device)\n",
        "\n",
        "# 전처리-트랜스폼 규칙 선언 # model1_train 코드의 validation set 의 트랜스폼 규칙과 동일하게 함\n",
        "transforms_test = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "# root 경로 폴더 속 jpg를 전처리, 텐서화 (rood 속에 폴더를 하나 더 만들어서 jpg를 묶어야 함)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/project/sample/test' ,\n",
        "                    transform = transforms_test)\n",
        "\n",
        "# DataLoader를 통해 네트워크에 올리기\n",
        "from torch.utils.data import Dataset,DataLoader \n",
        "testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 아웃풋, 로스, 프레딕, 아큐러시\n",
        "\n",
        "# output_list = []\n",
        "model6.eval() # 평가모드로 전환 # 평가모드와 학습모드의 layer 구성이 다르다\n",
        "correct = 0\n",
        "\n",
        "# 로스 연산을 위한\n",
        "import torch.nn.functional as F   # F : 테스트_로스 연산 함수\n",
        "test_loss = 0\n",
        "from tqdm import tqdm # 진행률 표시를 위한\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with torch.no_grad(): # 평가할 땐  gradient를 backpropagation 하지 않기 때문에 no grad로 gradient 계산을 막아서 연산 속도를 높인다\n",
        "            for data, target in tqdm(testloader):                                   \n",
        "                data, target  = data.to(device), target.to(device) \n",
        "                output = model6(data)   # model1에 데이터를 넣어서 아웃풋 > [a,b,c,d] 각 0,1,2,3 의 확률값 리턴 가장 큰 것이 pred\n",
        "                # output_list.append(output);\n",
        "                test_loss += F.nll_loss(output, target, reduction = 'sum').item()  # test_loss변수에 각 로스를 축적\n",
        "                pred = output.argmax(dim=1, keepdim=True) # argmax : 리스트에서 최댓값의 인덱스를 뽑아줌 > y값아웃풋인덱\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item() # accuracy 측정을 위한 변수 # 각 예측이 맞았는지 틀렸는지 correct변수에 축적 맞을 때마다 +1  # # view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다. #  view_as() 함수는 target 텐서를 view_as() 함수 안에 들어가는 인수(pred)의 모양대로 다시 정렬한다. #  pred.eq(data) : pred와 data가 일치하는지 검사\n",
        "test_loss /= len(testloader.dataset)  # 로스축적된 로스를 데이터 수(경로안jpg수)로 나누기\n",
        "\n",
        "# 아큐러시 출력 ( :.4f 소수점반올림 )\n",
        "# print('\\nTest set Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))  # 축적된 예측값을 데이터 개수로 나누기 *100 > 확률%값\n",
        "# 로스, 아큐러시 출력\n",
        "print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7-1nRxbckh7",
        "outputId": "f82738c4-faab-489f-8b71-0e357f1be0f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1154/1154 [03:13<00:00,  5.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average Loss: -0.1663, Accuracy: 276/1154 (23.9168%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y2I34TS8gg8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}